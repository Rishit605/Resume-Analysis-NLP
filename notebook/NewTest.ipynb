{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "absl-py                      2.1.0\n",
      "altair                       5.4.1\n",
      "asttokens                    2.4.1\n",
      "astunparse                   1.6.3\n",
      "attrs                        24.2.0\n",
      "blinker                      1.8.2\n",
      "cachetools                   5.5.0\n",
      "certifi                      2024.8.30\n",
      "cffi                         1.17.1\n",
      "charset-normalizer           3.4.0\n",
      "click                        8.1.7\n",
      "cloudpickle                  3.1.0\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.2\n",
      "contourpy                    1.3.0\n",
      "cryptography                 43.0.3\n",
      "cycler                       0.12.1\n",
      "debugpy                      1.8.7\n",
      "decorator                    5.1.1\n",
      "executing                    2.1.0\n",
      "flatbuffers                  24.3.25\n",
      "fonttools                    4.54.1\n",
      "future                       1.0.0\n",
      "gast                         0.6.0\n",
      "gensim                       4.3.3\n",
      "gitdb                        4.0.11\n",
      "GitPython                    3.1.43\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.67.0\n",
      "h5py                         3.12.1\n",
      "hyperopt                     0.2.7\n",
      "idna                         3.10\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.29.0\n",
      "jedi                         0.19.1\n",
      "Jinja2                       3.1.4\n",
      "joblib                       1.4.2\n",
      "jsonschema                   4.23.0\n",
      "jsonschema-specifications    2024.10.1\n",
      "jupyter_client               8.6.3\n",
      "jupyter_core                 5.7.2\n",
      "keras                        3.6.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.4.7\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.7\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   3.0.2\n",
      "matplotlib                   3.9.2\n",
      "matplotlib-inline            0.1.7\n",
      "mdurl                        0.1.2\n",
      "ml-dtypes                    0.4.1\n",
      "namex                        0.0.8\n",
      "narwhals                     1.10.0\n",
      "nest-asyncio                 1.6.0\n",
      "networkx                     3.4.2\n",
      "nltk                         3.9.1\n",
      "numpy                        1.26.4\n",
      "opt_einsum                   3.4.0\n",
      "optree                       0.13.0\n",
      "packaging                    24.1\n",
      "pandas                       2.2.3\n",
      "parso                        0.8.4\n",
      "pdfminer.six                 20240706\n",
      "pillow                       10.4.0\n",
      "pip                          24.0\n",
      "platformdirs                 4.3.6\n",
      "prompt_toolkit               3.0.48\n",
      "protobuf                     5.28.3\n",
      "psutil                       6.1.0\n",
      "pure_eval                    0.2.3\n",
      "py4j                         0.10.9.7\n",
      "pyarrow                      17.0.0\n",
      "pycparser                    2.22\n",
      "pydeck                       0.9.1\n",
      "Pygments                     2.18.0\n",
      "pyparsing                    3.2.0\n",
      "python-dateutil              2.9.0.post0\n",
      "pytz                         2024.2\n",
      "pywin32                      308\n",
      "pyzmq                        26.2.0\n",
      "referencing                  0.35.1\n",
      "regex                        2024.9.11\n",
      "requests                     2.32.3\n",
      "rich                         13.9.3\n",
      "rpds-py                      0.20.0\n",
      "scikit-learn                 1.5.2\n",
      "scipy                        1.13.1\n",
      "seaborn                      0.13.2\n",
      "setuptools                   69.5.1\n",
      "six                          1.16.0\n",
      "smart-open                   7.0.5\n",
      "smmap                        5.0.1\n",
      "stack-data                   0.6.3\n",
      "streamlit                    1.39.0\n",
      "tenacity                     9.0.0\n",
      "tensorboard                  2.18.0\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.18.0\n",
      "tensorflow_intel             2.18.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.5.0\n",
      "threadpoolctl                3.5.0\n",
      "toml                         0.10.2\n",
      "tornado                      6.4.1\n",
      "tqdm                         4.66.5\n",
      "traitlets                    5.14.3\n",
      "typing_extensions            4.12.2\n",
      "tzdata                       2024.2\n",
      "urllib3                      2.2.3\n",
      "watchdog                     5.0.3\n",
      "wcwidth                      0.2.13\n",
      "Werkzeug                     3.0.5\n",
      "wheel                        0.43.0\n",
      "wrapt                        1.16.0\n",
      "xgboost                      2.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text data...\n",
      "Found potentially problematic words:\n",
      "Problem word: ntp\n",
      "Problem word: ntp\n",
      "Found potentially problematic words:\n",
      "Problem word: npc\n",
      "Found potentially problematic words:\n",
      "Problem word: nac\n",
      "Problem word: nac\n",
      "Tokenizing text...\n",
      "Splitting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projs\\COde\\ResAnalysis\\resanalysis\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# Append the parent directory to the system path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from src.preprocessing.data_preprocessing import ResumeTextPreprocessor, NLPPreprocessor\n",
    "from src.training.training import call_data, create_and_compile_model\n",
    "from src.model.model import TextAnalysisModel2, TextClassifier\n",
    "\n",
    "from src.utils.helpers import plot_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b\"Free Flight Attendant Resume\\nDarlene Flint\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Corporate Flight Attendant Resume\\nCAITLIN F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Entry Level Resume Guide\\n\\nThis packet is i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Category                                             Resume\n",
       "0        1        HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...\n",
       "1        2        HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...\n",
       "2        3        HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...\n",
       "3        4        HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...\n",
       "4        5        HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...\n",
       "...    ...       ...                                                ...\n",
       "1214  1215  Aviation  b\"Free Flight Attendant Resume\\nDarlene Flint\\...\n",
       "1215  1216  Aviation  b'Corporate Flight Attendant Resume\\nCAITLIN F...\n",
       "1216  1217  Aviation  b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...\n",
       "1217  1218  Aviation  b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...\n",
       "1218  1219  Aviation  b'Entry Level Resume Guide\\n\\nThis packet is i...\n",
       "\n",
       "[1219 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = call_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b\"Free Flight Attendant Resume\\nDarlene Flint\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Corporate Flight Attendant Resume\\nCAITLIN F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Entry Level Resume Guide\\n\\nThis packet is i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Category                                             Resume\n",
       "0        1        HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...\n",
       "1        2        HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...\n",
       "2        3        HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...\n",
       "3        4        HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...\n",
       "4        5        HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...\n",
       "...    ...       ...                                                ...\n",
       "1214  1215  Aviation  b\"Free Flight Attendant Resume\\nDarlene Flint\\...\n",
       "1215  1216  Aviation  b'Corporate Flight Attendant Resume\\nCAITLIN F...\n",
       "1216  1217  Aviation  b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...\n",
       "1217  1218  Aviation  b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...\n",
       "1218  1219  Aviation  b'Entry Level Resume Guide\\n\\nThis packet is i...\n",
       "\n",
       "[1219 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found potentially problematic words:\n",
      "Problem word: ntp\n",
      "Problem word: ntp\n",
      "Found potentially problematic words:\n",
      "Problem word: npc\n",
      "Found potentially problematic words:\n",
      "Problem word: nac\n",
      "Problem word: nac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "data['cleaned_text'] = data['Resume'].apply(ResumeTextPreprocessor().process_and_check)\n",
    "\n",
    "max_words=10000\n",
    "max_length=500\n",
    "embedding_dim=100\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class AdvancedTextPreprocessor:\n",
    "    def __init__(self, language='english'):\n",
    "        \"\"\"\n",
    "        Advanced text preprocessor with multiple cleaning techniques\n",
    "        \n",
    "        Args:\n",
    "            language (str): Language for stopwords and processing\n",
    "        \"\"\"\n",
    "        self.stop_words = set(stopwords.words(language))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        Comprehensive text cleaning method\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text to clean\n",
    "        \n",
    "        Returns:\n",
    "            str: Cleaned and preprocessed text\n",
    "        \"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        cleaned_tokens = [\n",
    "            self.lemmatizer.lemmatize(token) \n",
    "            for token in tokens \n",
    "            if token not in self.stop_words and len(token) > 2\n",
    "        ]\n",
    "        \n",
    "        return ' '.join(cleaned_tokens)\n",
    "    \n",
    "    def preprocess_dataset(self, X):\n",
    "        \"\"\"\n",
    "        Apply text preprocessing to entire dataset\n",
    "        \n",
    "        Args:\n",
    "            X (array-like): Input text data\n",
    "        \n",
    "        Returns:\n",
    "            list: Preprocessed text data\n",
    "        \"\"\"\n",
    "        return [self.clean_text(text) for text in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_text_classification_pipeline(feat_col: str, tar_col: str, csv_path, max_words=5000, max_len=250):\n",
    "    \"\"\"\n",
    "    Advanced text classification pipeline with enhanced preprocessing\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to CSV file\n",
    "        test_size (float): Proportion of data for testing\n",
    "        max_words (int): Maximum number of words in vocabulary\n",
    "        max_len (int): Maximum sequence length\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of model, tokenizer, label encoder, and preprocessor\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(csv_path, pd.DataFrame):\n",
    "        # Load data\n",
    "        df = csv_path\n",
    "    else:\n",
    "        # Load data\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "    X = df[feat_col].values\n",
    "    y = df[tar_col].values\n",
    "    \n",
    "    # Advanced Text Preprocessing\n",
    "    preprocessor = AdvancedTextPreprocessor()\n",
    "    X_cleaned = preprocessor.preprocess_dataset(X)\n",
    "    \n",
    "    # Encode Labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    y_categorical = to_categorical(y_encoded)\n",
    "    num_classes = y_categorical.shape[1]\n",
    "    \n",
    "    # Tokenization\n",
    "    tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(X_cleaned)\n",
    "    X_sequences = tokenizer.texts_to_sequences(X_cleaned)\n",
    "    X_padded = pad_sequences(X_sequences, maxlen=max_len, truncating='post', padding='post')\n",
    "\n",
    "    return X_padded, y_categorical, num_classes, tokenizer, label_encoder\n",
    "\n",
    "\n",
    "def scaling(X, Y, test_size=0.2):    \n",
    "    # Split Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, \n",
    "        test_size=test_size, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad, y_pad, num_classes, tokenizer, label_encoder = advanced_text_classification_pipeline(csv_path=data, feat_col='Resume', tar_col='Category', max_len=max_length, max_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(975, 500)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = scaling(X_pad, y_pad)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "      <td>john smith phone box callahan greatresumesfast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "      <td>ame surname address mobile email personal prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "      <td>anthony brown assistant area expertise persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "      <td>www downloadmela com satheesh email career obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "      <td>human resource director expert organizational ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b\"Free Flight Attendant Resume\\nDarlene Flint\\...</td>\n",
       "      <td>free flight attendant resume darlene flint wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Corporate Flight Attendant Resume\\nCAITLIN F...</td>\n",
       "      <td>corporate flight attendant resume caitlin flan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...</td>\n",
       "      <td>major conrad preedom fairchild suite usaf acad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...</td>\n",
       "      <td>stacy sample cell email com qualification flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Entry Level Resume Guide\\n\\nThis packet is i...</td>\n",
       "      <td>entry level resume guide packet intended serve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Category                                             Resume  \\\n",
       "0        1        HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...   \n",
       "1        2        HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...   \n",
       "2        3        HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...   \n",
       "3        4        HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...   \n",
       "4        5        HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...   \n",
       "...    ...       ...                                                ...   \n",
       "1214  1215  Aviation  b\"Free Flight Attendant Resume\\nDarlene Flint\\...   \n",
       "1215  1216  Aviation  b'Corporate Flight Attendant Resume\\nCAITLIN F...   \n",
       "1216  1217  Aviation  b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...   \n",
       "1217  1218  Aviation  b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...   \n",
       "1218  1219  Aviation  b'Entry Level Resume Guide\\n\\nThis packet is i...   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0     john smith phone box callahan greatresumesfast...  \n",
       "1     ame surname address mobile email personal prof...  \n",
       "2     anthony brown assistant area expertise persona...  \n",
       "3     www downloadmela com satheesh email career obj...  \n",
       "4     human resource director expert organizational ...  \n",
       "...                                                 ...  \n",
       "1214  free flight attendant resume darlene flint wes...  \n",
       "1215  corporate flight attendant resume caitlin flan...  \n",
       "1216  major conrad preedom fairchild suite usaf acad...  \n",
       "1217  stacy sample cell email com qualification flig...  \n",
       "1218  entry level resume guide packet intended serve...  \n",
       "\n",
       "[1219 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Accountant'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = label_encoder.transform(data['Category'][-1:])\n",
    "tT = to_categorical(t)\n",
    "tT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Designing'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([np.argmax(y_test[-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'street red fort old  mail    position assistant bank manager utilize skill knowledge experience  xefxxb seven year experience assistant branch manager various international domestic  excellent presentation interpersonal  xefxxb instrumental opening two hundred new saving  xefxxb extensive knowledge rapport  xefxxb possess good leadership   international bank new jersey    xefxxb handling procedure  opening saving accountsnxefxxb increasing business networking building new client  xefxxb assisting manager identifying sale opportunity  xefxxb updating daily report  xefxxb training overseeing performance  xefxxb planning implementing strategy increase customer  ensuring  stock order per norm   new jersey  banking analyst  conducted presented industry research reportsnxefxxb participated equity structuring  performed task financial analysisnxefxxb built utilized effective financial  conducted research credit debt capital  united banking organization new jersey nyn  banking analystnxefxxb assisted client senior management senior banker executing capital market transactionsnxefxxb handled task defining value entity capital raising  generated effective financial model analyze pro  effect forecast financial  analyzed  cash flow weighted average cost capital company  qualification ngraduate commerce  college art  graduate commerce university new jersey'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in tokenizer.word_index.items()])\n",
    "original_text = ' '.join([reverse_word_index.get(i, '?') for i in X_train[-1]])\n",
    "original_text = original_text.replace('<OOV>', '')\n",
    "original_text = original_text.replace('?', '')\n",
    "original_text = original_text.rstrip()\n",
    "original_text = original_text.lstrip()\n",
    "original_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projs\\COde\\ResAnalysis\\resanalysis\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 887ms/step - accuracy: 0.0664 - loss: 4.1110 - val_accuracy: 0.0718 - val_loss: 3.4468\n",
      "Epoch 2/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 774ms/step - accuracy: 0.1430 - loss: 3.4734 - val_accuracy: 0.0564 - val_loss: 3.4275\n",
      "Epoch 3/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 783ms/step - accuracy: 0.2506 - loss: 2.9483 - val_accuracy: 0.0564 - val_loss: 3.4101\n",
      "Epoch 4/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 789ms/step - accuracy: 0.3707 - loss: 2.5287 - val_accuracy: 0.0821 - val_loss: 3.3944\n",
      "Epoch 5/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 820ms/step - accuracy: 0.4831 - loss: 2.0881 - val_accuracy: 0.0872 - val_loss: 3.3786\n",
      "Epoch 6/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 837ms/step - accuracy: 0.5275 - loss: 1.9074 - val_accuracy: 0.1026 - val_loss: 3.3650\n",
      "Epoch 7/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 821ms/step - accuracy: 0.5948 - loss: 1.6073 - val_accuracy: 0.1333 - val_loss: 3.3525\n",
      "Epoch 8/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 841ms/step - accuracy: 0.6789 - loss: 1.4563 - val_accuracy: 0.1795 - val_loss: 3.3404\n",
      "Epoch 9/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 852ms/step - accuracy: 0.6956 - loss: 1.3414 - val_accuracy: 0.1385 - val_loss: 3.3317\n",
      "Epoch 10/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 853ms/step - accuracy: 0.7923 - loss: 1.1296 - val_accuracy: 0.1282 - val_loss: 3.3224\n",
      "Epoch 11/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 841ms/step - accuracy: 0.8009 - loss: 1.0452 - val_accuracy: 0.1949 - val_loss: 3.3041\n",
      "Epoch 12/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 838ms/step - accuracy: 0.8186 - loss: 1.0203 - val_accuracy: 0.1692 - val_loss: 3.2920\n",
      "Epoch 13/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 855ms/step - accuracy: 0.8317 - loss: 0.9541 - val_accuracy: 0.1795 - val_loss: 3.2719\n",
      "Epoch 14/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 897ms/step - accuracy: 0.8470 - loss: 0.8795 - val_accuracy: 0.1744 - val_loss: 3.2680\n",
      "Epoch 15/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 900ms/step - accuracy: 0.8355 - loss: 0.9135 - val_accuracy: 0.1744 - val_loss: 3.2549\n",
      "Epoch 16/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 867ms/step - accuracy: 0.8822 - loss: 0.7456 - val_accuracy: 0.1795 - val_loss: 3.2266\n",
      "Epoch 17/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 869ms/step - accuracy: 0.8744 - loss: 0.7860 - val_accuracy: 0.1897 - val_loss: 3.2024\n",
      "Epoch 18/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 892ms/step - accuracy: 0.8995 - loss: 0.7225 - val_accuracy: 0.2359 - val_loss: 3.1682\n",
      "Epoch 19/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 889ms/step - accuracy: 0.8827 - loss: 0.6484 - val_accuracy: 0.2564 - val_loss: 3.1353\n",
      "Epoch 20/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 890ms/step - accuracy: 0.9095 - loss: 0.6470 - val_accuracy: 0.2205 - val_loss: 3.1060\n",
      "Epoch 21/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 905ms/step - accuracy: 0.9141 - loss: 0.6489 - val_accuracy: 0.2462 - val_loss: 3.0856\n",
      "Epoch 22/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 915ms/step - accuracy: 0.9185 - loss: 0.6374 - val_accuracy: 0.1590 - val_loss: 3.0888\n",
      "Epoch 23/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 898ms/step - accuracy: 0.9327 - loss: 0.5284 - val_accuracy: 0.3026 - val_loss: 2.9956\n",
      "Epoch 24/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 892ms/step - accuracy: 0.9263 - loss: 0.5681 - val_accuracy: 0.2205 - val_loss: 2.9673\n",
      "Epoch 25/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 907ms/step - accuracy: 0.9129 - loss: 0.5916 - val_accuracy: 0.2410 - val_loss: 2.9817\n",
      "Epoch 26/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 919ms/step - accuracy: 0.9420 - loss: 0.5145 - val_accuracy: 0.2462 - val_loss: 2.9210\n",
      "Epoch 27/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 911ms/step - accuracy: 0.9305 - loss: 0.5543 - val_accuracy: 0.2308 - val_loss: 2.8719\n",
      "Epoch 28/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 893ms/step - accuracy: 0.9487 - loss: 0.4921 - val_accuracy: 0.2410 - val_loss: 2.9520\n",
      "Epoch 29/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 882ms/step - accuracy: 0.9501 - loss: 0.5312 - val_accuracy: 0.3333 - val_loss: 2.8274\n",
      "Epoch 30/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 888ms/step - accuracy: 0.9358 - loss: 0.4845 - val_accuracy: 0.2974 - val_loss: 2.7419\n",
      "Epoch 31/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 918ms/step - accuracy: 0.9462 - loss: 0.4888 - val_accuracy: 0.3846 - val_loss: 2.6405\n",
      "Epoch 32/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 934ms/step - accuracy: 0.9425 - loss: 0.4530 - val_accuracy: 0.4256 - val_loss: 2.6243\n",
      "Epoch 33/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 910ms/step - accuracy: 0.9421 - loss: 0.4494 - val_accuracy: 0.4410 - val_loss: 2.5549\n",
      "Epoch 34/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 881ms/step - accuracy: 0.9401 - loss: 0.4592 - val_accuracy: 0.4154 - val_loss: 2.5523\n",
      "Epoch 35/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 891ms/step - accuracy: 0.9477 - loss: 0.4760 - val_accuracy: 0.4359 - val_loss: 2.4957\n",
      "Epoch 36/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 905ms/step - accuracy: 0.9487 - loss: 0.4064 - val_accuracy: 0.4000 - val_loss: 2.4003\n",
      "Epoch 37/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 848ms/step - accuracy: 0.9394 - loss: 0.4468 - val_accuracy: 0.4103 - val_loss: 2.4022\n",
      "Epoch 38/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 846ms/step - accuracy: 0.9407 - loss: 0.4634 - val_accuracy: 0.4462 - val_loss: 2.4806\n",
      "Epoch 39/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 862ms/step - accuracy: 0.9593 - loss: 0.4100 - val_accuracy: 0.4205 - val_loss: 2.4457\n",
      "Epoch 40/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 882ms/step - accuracy: 0.9525 - loss: 0.4138 - val_accuracy: 0.4564 - val_loss: 2.3669\n",
      "Epoch 41/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 886ms/step - accuracy: 0.9553 - loss: 0.3909 - val_accuracy: 0.4308 - val_loss: 2.3474\n",
      "Epoch 42/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.9457 - loss: 0.4265 - val_accuracy: 0.2359 - val_loss: 2.9336\n",
      "Epoch 43/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9388 - loss: 0.4240 - val_accuracy: 0.2154 - val_loss: 3.0988\n",
      "Epoch 44/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.9509 - loss: 0.3851 - val_accuracy: 0.2564 - val_loss: 2.7923\n",
      "Epoch 45/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.9488 - loss: 0.3980 - val_accuracy: 0.2564 - val_loss: 2.6439\n",
      "Epoch 46/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.9640 - loss: 0.3546 - val_accuracy: 0.4051 - val_loss: 2.3012\n",
      "Epoch 47/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.9394 - loss: 0.4223 - val_accuracy: 0.4462 - val_loss: 2.1744\n",
      "Epoch 48/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3s/step - accuracy: 0.9460 - loss: 0.4055 - val_accuracy: 0.3692 - val_loss: 2.4478\n",
      "Epoch 49/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9601 - loss: 0.3373 - val_accuracy: 0.4103 - val_loss: 2.2890\n",
      "Epoch 50/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9523 - loss: 0.3825 - val_accuracy: 0.4513 - val_loss: 2.3450\n",
      "Epoch 51/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9461 - loss: 0.4118 - val_accuracy: 0.4462 - val_loss: 2.2070\n",
      "Epoch 52/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.9440 - loss: 0.3828 - val_accuracy: 0.4000 - val_loss: 2.2522\n",
      "Epoch 53/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.9569 - loss: 0.3699 - val_accuracy: 0.4359 - val_loss: 2.2292\n",
      "Epoch 54/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.9710 - loss: 0.3084 - val_accuracy: 0.4256 - val_loss: 2.2941\n",
      "Epoch 55/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9487 - loss: 0.3632 - val_accuracy: 0.4308 - val_loss: 2.3041\n",
      "Epoch 56/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9446 - loss: 0.4100 - val_accuracy: 0.4718 - val_loss: 2.1985\n",
      "Epoch 57/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.9549 - loss: 0.3579 - val_accuracy: 0.5128 - val_loss: 2.0674\n",
      "Epoch 58/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.9570 - loss: 0.3483 - val_accuracy: 0.5026 - val_loss: 2.0139\n",
      "Epoch 59/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9577 - loss: 0.3489 - val_accuracy: 0.4667 - val_loss: 2.1473\n",
      "Epoch 60/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9649 - loss: 0.3277 - val_accuracy: 0.4615 - val_loss: 2.2196\n",
      "Epoch 61/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9725 - loss: 0.3054 - val_accuracy: 0.4564 - val_loss: 2.1877\n",
      "Epoch 62/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.9543 - loss: 0.3433 - val_accuracy: 0.4615 - val_loss: 2.0675\n",
      "Epoch 63/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.9448 - loss: 0.3518 - val_accuracy: 0.4923 - val_loss: 2.1312\n",
      "Epoch 64/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.9585 - loss: 0.3339 - val_accuracy: 0.4410 - val_loss: 2.2786\n",
      "Epoch 65/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.9617 - loss: 0.3167 - val_accuracy: 0.3897 - val_loss: 2.4365\n",
      "Epoch 66/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.9583 - loss: 0.3721 - val_accuracy: 0.4103 - val_loss: 2.5381\n",
      "Epoch 67/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.9536 - loss: 0.3688 - val_accuracy: 0.4103 - val_loss: 2.4229\n",
      "Epoch 68/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.9637 - loss: 0.2914 - val_accuracy: 0.4872 - val_loss: 2.2725\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - accuracy: 0.5973 - loss: 1.8368\n",
      "Test Accuracy: 60.66%\n"
     ]
    }
   ],
   "source": [
    "# Build Advanced Model with More Complexity\n",
    "model = tf.keras.Sequential([\n",
    "    # Embedding layer with more dimensions\n",
    "    tf.keras.layers.Embedding(max_words, 64, input_length=max_length),\n",
    "    \n",
    "    # Bidirectional LSTM for capturing context\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True)\n",
    "    ),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    \n",
    "    # More dense layers with regularization\n",
    "    tf.keras.layers.Dense(128, activation='relu', \n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(64, activation='relu', \n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile with learning rate scheduling\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early Stopping and Model Checkpointing\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_model.keras', \n",
    "    save_best_only=True, \n",
    "    monitor='val_accuracy'\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(None,))\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_words, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projs\\COde\\ResAnalysis\\resanalysis\\Lib\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.0516 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0527 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0529 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0515 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0546 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0468 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0509 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0588 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0497 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0546 - loss: 0.0000e+00 - val_accuracy: 0.0513 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d79dd49550>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.fit(data2['X_train'], data2['y_train'], validation_data=(data2['X_val'], data2['y_val']), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text, model, tokenizer, label_encoder, preprocessor, max_len=250):\n",
    "    \"\"\"\n",
    "    Predict category for a new text\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to classify\n",
    "        model (tf.keras.Model): Trained model\n",
    "        tokenizer (Tokenizer): Fitted tokenizer\n",
    "        label_encoder (LabelEncoder): Fitted label encoder\n",
    "        preprocessor (AdvancedTextPreprocessor): Text preprocessor\n",
    "        max_len (int): Maximum sequence length\n",
    "    \n",
    "    Returns:\n",
    "        str: Predicted category\n",
    "    \"\"\"\n",
    "    # Preprocess text\n",
    "    cleaned_text = preprocessor.clean_text(text)\n",
    "    \n",
    "    # Tokenize and pad\n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, truncating='post', padding='post')\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    predicted_class_index = np.argmax(prediction)\n",
    "    \n",
    "    # Get original label\n",
    "    predicted_category = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "    \n",
    "    return predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    1,    1,    1,    1,    1,    1,  550,    1, 6877,  252,\n",
       "         34, 5848,  459,  488,    1,    1,    1, 2854,  994,    3,    1,\n",
       "          1, 5848,    1,    3, 8370, 8440, 5848,  459,    1, 4321,    1,\n",
       "        115, 3075,  194, 2855, 1942,    1,  894, 3075, 2733,   14,    1,\n",
       "       3075, 2733, 3643,    1, 5848, 2733, 4321, 3786, 1669,    1, 1525,\n",
       "          1,  540,    1, 4321,    1,  222,  142, 1768,    1,    1,    1,\n",
       "         33,   10,    1, 3075,  149,  110, 3628,    1,  359,    1, 2097,\n",
       "       5848,   20,    1,   16, 1038,  306,    1,    1, 4321, 2733,    1,\n",
       "       4321,    1,  581,  667,    1, 1388,    1,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'clean_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredict_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[141], line 17\u001b[0m, in \u001b[0;36mpredict_category\u001b[1;34m(text, model, tokenizer, label_encoder, preprocessor, max_len)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mPredict category for a new text\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    str: Predicted category\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Preprocess text\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m cleaned_text \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_text\u001b[49m(text)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Tokenize and pad\u001b[39;00m\n\u001b[0;32m     20\u001b[0m sequence \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences([cleaned_text])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'clean_text'"
     ]
    }
   ],
   "source": [
    "predict_category(data['Resume'][-1:].values, model, tokenizer, label_encoder, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BPO'], dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([np.argmax(X_test[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 7121,  340, 1806, 3189,    1,    1,    1,    1,    1, 7121,\n",
       "        340, 1806, 3189,    1, 7121,  340, 1806, 3189,    1,    1,    1,\n",
       "          1,    1, 8913,    1,    1,  332,    1, 8913, 8913, 8913, 8913,\n",
       "       8913,    1,    1,    1, 7121,  340, 1806, 3189,    1,   49,  421,\n",
       "          1,   48,    1,   49,  421,    1,    1,    1,    4,    1,    1,\n",
       "         63,    1,    1,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'healthcare nurse resume   south  crest xexxa   xexxa cell xexxa email    health   mental health nurse decade  experience providing  care acute  well planned implemented professional nursing care  accordance hospital policy regulation  job function executed nursing process based  experience coordinated provided safe patient care  awareness age appropriate culturally aware  responded patient message query related  problem routine report concern  behavior  issue fall within nursing scope addition  knowledge modern psychiatric nursing theory  procedure well problem mental illness    counseling   supervision   maintenance   health   health  healthcare company xexx atlanta july xexx mar nxexxa administered oral  medication oversaw dispensing   medication  kept accurate written record patient care provided including  treatment plan progress note medication administered  planningnxexxa educated patient family member patientxexxs  medication daily living skillsnxexxa observed assessed change trend physical mental condition ofnthe patient well planned implemented therapeutic intervention  response  conducted evaluated class  group  therapy  health  partner xexx  may xexx july nxexxa coordinated taught educational mental health care program meet  staff patient caregiver  developed revised plan care mental health patient  coordinated patient care staff member  provided patient intervention home setting using current   respected patientxexxs privacy maintained  science nursing  xexx college medicine xexx'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in tokenizer.word_index.items()])\n",
    "original_text = ' '.join([reverse_word_index.get(i, '?') for i in X_test[0]])\n",
    "original_text = original_text.replace('<OOV>', '')\n",
    "original_text = original_text.replace('?', '')\n",
    "original_text = original_text.rstrip()\n",
    "original_text = original_text.lstrip()\n",
    "original_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Health & Fitness'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Predict\n",
    "prediction = model.predict(X_test[0].reshape(1, -1))\n",
    "predicted_class_index = np.argmax(prediction)\n",
    "# predicted_class_index\n",
    "# # Get original label\n",
    "predicted_category = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_category()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 15, 15, 16, 16, 24, 23, 14, 21, 15,  1, 11, 15,  5,  0, 21, 20,\n",
       "       16, 10, 16,  4, 16,  7, 21, 15, 11, 21, 22, 15,  9,  9, 19, 14, 22,\n",
       "       22,  5,  0,  5, 15, 16, 21,  1,  9,  9, 19, 17, 21, 13, 11,  9, 22,\n",
       "        9, 21, 19,  2, 13, 15, 13, 19, 14,  0,  9, 23, 14,  0, 11, 13,  2,\n",
       "        9, 22, 20, 20, 15, 17, 19,  4, 21, 15,  0, 23, 19,  9, 16, 17, 17,\n",
       "       20, 18,  5, 15, 16, 21, 16, 14, 22,  6, 21, 23, 17, 20, 15, 12, 19,\n",
       "       21, 16, 16, 16, 18, 22, 18, 24, 20, 24, 21, 16, 21, 24, 11, 15, 11,\n",
       "       10, 17, 16, 21,  1, 16, 17, 15, 17,  5, 24, 17, 15, 13, 13,  0, 16,\n",
       "        1, 15, 15,  1,  1, 16, 18, 17, 15, 15, 16, 20, 11, 20, 16,  1,  0,\n",
       "        7, 12, 15, 15,  5, 21,  0,  1, 24,  9, 24,  6,  3, 21,  9, 12, 20,\n",
       "        8,  1,  8, 20, 21,  2, 16, 24, 17,  0,  0,  2, 16, 16, 17,  1, 22,\n",
       "        9, 16,  2, 11,  1,  9, 24, 20,  0,  9,  1,  0, 19, 14, 24, 14, 22,\n",
       "       14,  0,  5, 12, 24, 11, 15, 16,  9, 11, 15, 17, 12,  9, 14, 16, 10,\n",
       "       21,  1,  9,  3, 13, 20, 16, 13,  1, 13, 15,  5, 17, 24, 10, 21,  7,\n",
       "       17, 16, 22, 14, 14, 19,  7, 11,  5, 12, 24, 16, 17,  3, 16, 19, 24,\n",
       "       14, 18, 22, 11, 22, 22,  4, 11, 20, 15,  1, 22, 11,  1, 21, 16, 17,\n",
       "        1, 16, 15, 15, 16, 24, 15, 16, 16, 16, 17,  6,  0, 20,  1, 14, 15,\n",
       "       14, 12,  9, 24, 11, 24, 16, 13, 18, 12, 20, 12, 11, 11, 16,  8, 23,\n",
       "       24, 22, 20, 21, 16, 24, 19,  8,  8, 16, 16, 15, 13,  9, 24, 21, 21,\n",
       "       16, 12,  3, 10, 17, 15, 14, 18,  8, 20, 17, 16, 14, 22, 15,  2, 16,\n",
       "        9,  0, 12, 18, 21,  0, 17, 22, 16, 22, 17,  9, 22, 16, 17, 24, 18,\n",
       "       14, 21,  1, 20, 15, 13, 13,  1, 17, 15, 23,  1,  3, 12,  0, 15,  3,\n",
       "       24,  4, 18,  5, 22, 22, 20, 16, 22,  1, 10,  5, 16, 16, 15,  1, 16,\n",
       "       22, 15, 14, 20, 16, 20, 18,  0, 11, 21, 14, 21, 19,  6,  4, 19, 21,\n",
       "       22, 10, 10, 22,  9, 19,  7, 21, 21, 12,  6, 17, 13, 19, 21,  8, 13,\n",
       "        9, 21, 13, 21,  1,  1,  5,  9, 24, 15,  8, 15, 21, 16, 12, 22, 24,\n",
       "       10, 21, 13, 19,  0, 20, 15, 20, 19,  1, 21,  6, 17,  0,  0, 17,  0,\n",
       "       21, 22, 14, 18,  6, 14, 24, 17, 17,  3,  4, 21, 16,  6,  0, 11, 12,\n",
       "       11,  9, 15, 13, 11, 16,  0,  0,  0, 17,  5, 15,  9, 10,  5, 20,  1,\n",
       "       24,  6, 20,  1, 13, 15, 20, 20, 15, 16,  1, 10, 15, 19, 11, 22, 13,\n",
       "       21,  0, 21,  5, 16, 20, 17,  1, 20, 15,  6,  2,  6, 14,  0, 20, 21,\n",
       "       22, 22, 16, 17,  5, 13, 22,  2,  2, 20, 19, 21, 22, 11,  1, 14, 16,\n",
       "       20,  0, 22, 22,  8, 20, 19,  2, 15,  7, 16,  1, 12, 10,  4, 24, 17,\n",
       "        9,  8, 20,  0,  0, 16,  6, 13, 16, 16, 13, 20,  0, 24, 16, 10, 21,\n",
       "       14, 19, 15, 20, 16, 14,  6, 15,  2,  1, 16,  6,  1, 13,  8,  7, 17,\n",
       "        8,  0, 21, 22, 17, 15, 16, 16, 21, 15,  1, 20, 18, 11, 22,  5, 14,\n",
       "       16,  9, 23, 13, 16, 15, 19, 24,  8, 21, 21, 24, 15, 24, 15, 13, 22,\n",
       "       16,  0,  1, 15, 20,  3,  5,  5, 21, 15, 16, 21, 22,  9, 22,  5, 10,\n",
       "       15, 15, 13, 15, 22,  5, 21, 21,  0,  1, 13, 13, 21, 24, 21,  5, 14,\n",
       "        1, 21, 24, 21, 21, 22, 10, 10,  6, 24, 21, 17, 17, 20,  9, 11, 22,\n",
       "       16,  2, 16, 24,  6, 16, 10, 16, 13, 21, 21,  0, 17, 16, 19,  8, 15,\n",
       "       20, 21,  9,  0,  3, 22, 17, 24,  6, 21,  6, 20,  0, 16, 21, 22, 17,\n",
       "       20, 13, 23, 15,  2,  0, 20,  5, 20, 24,  1, 15,  0,  7, 22, 13, 12,\n",
       "       10, 15, 20, 24, 13, 17, 19, 20,  5, 16, 15, 14, 11, 14, 20,  2, 20,\n",
       "       16, 24, 14, 20, 14, 14, 20, 21,  8,  0,  8, 21, 11,  0, 22, 21, 11,\n",
       "       17,  5, 19, 14, 21,  2,  0, 19,  5,  4, 18, 10, 22,  5, 15])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "def train_model(train_dataset, val_dataset, vocab_size, embed_dim, max_length, num_classes, embedding_matrix=None):\n",
    "    # Initialize model\n",
    "    model = TextClassifier(vocab_size, embed_dim, max_length, num_classes, embedding_matrix)\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_steps = 1000\n",
    "    decay_rate = 0.9\n",
    "    learning_rate_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps, decay_rate\n",
    "    )\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        # tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        #     monitor='val_loss',\n",
    "        #     factor=0.5,\n",
    "        #     patience=3,\n",
    "        #     min_lr=0.00001\n",
    "        # )\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=30,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "      <td>john smith phone box callahan greatresumesfast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "      <td>ame surname address mobile email personal prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "      <td>anthony brown assistant area expertise persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "      <td>www downloadmela com satheesh email career obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "      <td>human resource director expert organizational ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b\"Free Flight Attendant Resume\\nDarlene Flint\\...</td>\n",
       "      <td>free flight attendant resume darlene flint wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Corporate Flight Attendant Resume\\nCAITLIN F...</td>\n",
       "      <td>corporate flight attendant resume caitlin flan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...</td>\n",
       "      <td>major conrad preedom fairchild suite usaf acad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...</td>\n",
       "      <td>stacy sample cell email com qualification flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Entry Level Resume Guide\\n\\nThis packet is i...</td>\n",
       "      <td>entry level resume guide packet intended serve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Category                                             Resume  \\\n",
       "0        1        HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...   \n",
       "1        2        HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...   \n",
       "2        3        HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...   \n",
       "3        4        HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...   \n",
       "4        5        HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...   \n",
       "...    ...       ...                                                ...   \n",
       "1214  1215  Aviation  b\"Free Flight Attendant Resume\\nDarlene Flint\\...   \n",
       "1215  1216  Aviation  b'Corporate Flight Attendant Resume\\nCAITLIN F...   \n",
       "1216  1217  Aviation  b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...   \n",
       "1217  1218  Aviation  b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...   \n",
       "1218  1219  Aviation  b'Entry Level Resume Guide\\n\\nThis packet is i...   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0     john smith phone box callahan greatresumesfast...  \n",
       "1     ame surname address mobile email personal prof...  \n",
       "2     anthony brown assistant area expertise persona...  \n",
       "3     www downloadmela com satheesh email career obj...  \n",
       "4     human resource director expert organizational ...  \n",
       "...                                                 ...  \n",
       "1214  free flight attendant resume darlene flint wes...  \n",
       "1215  corporate flight attendant resume caitlin flan...  \n",
       "1216  major conrad preedom fairchild suite usaf acad...  \n",
       "1217  stacy sample cell email com qualification flig...  \n",
       "1218  entry level resume guide packet intended serve...  \n",
       "\n",
       "[1219 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found potentially problematic words:\n",
      "Problem word: ntp\n",
      "Problem word: ntp\n",
      "Found potentially problematic words:\n",
      "Problem word: npc\n",
      "Found potentially problematic words:\n",
      "Problem word: nac\n",
      "Problem word: nac\n",
      "Analyzing text characteristics...\n",
      "Average length: 607.49\n",
      "Median length: 317.00\n",
      "95th percentile length: 2605.00\n",
      "Max length: 6149\n",
      "Total unique words: 32427\n",
      "Words appearing only once: 12713\n",
      "Tokenizing texts...\n",
      "Creating Word2Vec embeddings...\n",
      "Splitting data...\n",
      "Creating TF datasets...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projs\\COde\\ResAnalysis\\resanalysis\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.0536 - loss: 4.1491 - val_accuracy: 0.1538 - val_loss: 3.4101\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.1840 - loss: 3.0358 - val_accuracy: 0.1846 - val_loss: 3.2006\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2732 - loss: 2.7229 - val_accuracy: 0.2256 - val_loss: 2.9534\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3097 - loss: 2.4287 - val_accuracy: 0.2256 - val_loss: 2.7831\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4077 - loss: 2.1093 - val_accuracy: 0.2923 - val_loss: 2.4193\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4390 - loss: 1.9806 - val_accuracy: 0.3179 - val_loss: 2.3408\n",
      "Epoch 7/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4717 - loss: 1.8321 - val_accuracy: 0.3538 - val_loss: 2.2046\n",
      "Epoch 8/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5063 - loss: 1.7730 - val_accuracy: 0.3897 - val_loss: 2.0954\n",
      "Epoch 9/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5590 - loss: 1.5560 - val_accuracy: 0.4308 - val_loss: 2.0096\n",
      "Epoch 10/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5562 - loss: 1.5680 - val_accuracy: 0.4513 - val_loss: 1.9808\n",
      "Epoch 11/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6010 - loss: 1.3891 - val_accuracy: 0.4410 - val_loss: 1.9381\n",
      "Epoch 12/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6273 - loss: 1.2650 - val_accuracy: 0.4462 - val_loss: 1.8417\n",
      "Epoch 13/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6370 - loss: 1.2524 - val_accuracy: 0.4615 - val_loss: 1.8735\n",
      "Epoch 14/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6962 - loss: 1.1112 - val_accuracy: 0.4667 - val_loss: 1.8977\n",
      "Epoch 15/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6543 - loss: 1.1774 - val_accuracy: 0.5077 - val_loss: 1.8288\n",
      "Epoch 16/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7149 - loss: 0.9950 - val_accuracy: 0.4923 - val_loss: 1.7347\n",
      "Epoch 17/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7077 - loss: 0.9434 - val_accuracy: 0.4872 - val_loss: 1.7059\n",
      "Epoch 18/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7057 - loss: 0.9989 - val_accuracy: 0.4872 - val_loss: 1.7527\n",
      "Epoch 19/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7147 - loss: 0.9224 - val_accuracy: 0.5179 - val_loss: 1.7506\n",
      "Epoch 20/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7565 - loss: 0.8458 - val_accuracy: 0.5077 - val_loss: 1.7492\n",
      "Epoch 21/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7547 - loss: 0.8022 - val_accuracy: 0.5128 - val_loss: 1.7240\n",
      "Epoch 22/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7762 - loss: 0.7283 - val_accuracy: 0.5231 - val_loss: 1.7208\n",
      "Epoch 23/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7851 - loss: 0.6954 - val_accuracy: 0.4769 - val_loss: 1.7998\n",
      "Epoch 24/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7996 - loss: 0.7004 - val_accuracy: 0.5026 - val_loss: 1.8673\n",
      "Epoch 25/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7914 - loss: 0.7147 - val_accuracy: 0.5026 - val_loss: 1.8469\n",
      "Epoch 26/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8172 - loss: 0.6007 - val_accuracy: 0.5026 - val_loss: 1.7983\n",
      "Epoch 27/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8475 - loss: 0.5499 - val_accuracy: 0.5282 - val_loss: 1.8317\n"
     ]
    }
   ],
   "source": [
    "data['cleaned_text'] = data['Resume'].apply(ResumeTextPreprocessor().process_and_check)\n",
    "\n",
    "# Using your preprocessor\n",
    "preprocessor = NLPPreprocessor(max_words=10000, max_length=500, embedding_dim=100)\n",
    "data2 = preprocessor.prepare_data(\n",
    "    texts=data['cleaned_text'],\n",
    "    labels=data['Category'],\n",
    "    use_word2vec=True  # Use Word2Vec embeddings\n",
    ")\n",
    "# data2\n",
    "\n",
    "if data2['embedding_matrix'] is not None:\n",
    "        vocab_size = data2['embedding_matrix'].shape[0] \n",
    "    \n",
    "\n",
    "# Train model\n",
    "model, history = train_model(\n",
    "    data2['train_dataset'],\n",
    "    data2['val_dataset'],\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=100,\n",
    "    max_length=500,\n",
    "    num_classes=data2['num_classes'],\n",
    "    embedding_matrix=data2['embedding_matrix']\n",
    ")\n",
    "\n",
    "\n",
    "# # In your create_model function, ensure the embedding layer is initialized correctly\n",
    "# def create_model(vocab_size, embedding_dim, num_classes, embedding_matrix=None):\n",
    "#     if embedding_matrix is not None:\n",
    "#         vocab_size = embedding_matrix.shape[0]  # Use the size of the embedding matrix\n",
    "\n",
    "    \n",
    "#     model = TextAnalysisModel2(\n",
    "#         vocab_size=vocab_size,\n",
    "#         embed_dim=embedding_dim,\n",
    "#         max_length=500,  # Default max_length, adjust as needed\n",
    "#         conv_units=64,\n",
    "#         dense_units=64,\n",
    "#         output=num_classes,\n",
    "#         kernels=3,\n",
    "#         regularizer=0.01,\n",
    "#         dropout=0.5,\n",
    "#         # Ensure the embedding layer is initialized to accept weights\n",
    "#         embedding_matrix=embedding_matrix\n",
    "#     )\n",
    "    \n",
    "#     if embedding_matrix is not None:\n",
    "#         model.embedding.trainable = False  # Freeze embedding layer if using Word2Vec\n",
    "    \n",
    "#     model.compile(\n",
    "#         optimizer='adam',\n",
    "#         loss='sparse_categorical_crossentropy',\n",
    "#         metrics=['categorical_accuracy']\n",
    "#     )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from src.utils.helpers import plot_accuracy\n",
    "\n",
    "plot_accuracy(history, 'accuracy', 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 15, 15, 16, 16, 24, 23, 14, 21, 15,  1, 11, 15,  5,  0, 21, 20,\n",
       "       16, 10, 16,  4, 16,  7, 21, 15, 11, 21, 22, 15,  9,  9, 19, 14, 22,\n",
       "       22,  5,  0,  5, 15, 16, 21,  1,  9,  9, 19, 17, 21, 13, 11,  9, 22,\n",
       "        9, 21, 19,  2, 13, 15, 13, 19, 14,  0,  9, 23, 14,  0, 11, 13,  2,\n",
       "        9, 22, 20, 20, 15, 17, 19,  4, 21, 15,  0, 23, 19,  9, 16, 17, 17,\n",
       "       20, 18,  5, 15, 16, 21, 16, 14, 22,  6, 21, 23, 17, 20, 15, 12, 19,\n",
       "       21, 16, 16, 16, 18, 22, 18, 24, 20, 24, 21, 16, 21, 24, 11, 15, 11,\n",
       "       10, 17, 16, 21,  1, 16, 17, 15, 17,  5, 24, 17, 15, 13, 13,  0, 16,\n",
       "        1, 15, 15,  1,  1, 16, 18, 17, 15, 15, 16, 20, 11, 20, 16,  1,  0,\n",
       "        7, 12, 15, 15,  5, 21,  0,  1, 24,  9, 24,  6,  3, 21,  9, 12, 20,\n",
       "        8,  1,  8, 20, 21,  2, 16, 24, 17,  0,  0,  2, 16, 16, 17,  1, 22,\n",
       "        9, 16,  2, 11,  1,  9, 24, 20,  0,  9,  1,  0, 19, 14, 24, 14, 22,\n",
       "       14,  0,  5, 12, 24, 11, 15, 16,  9, 11, 15, 17, 12,  9, 14, 16, 10,\n",
       "       21,  1,  9,  3, 13, 20, 16, 13,  1, 13, 15,  5, 17, 24, 10, 21,  7,\n",
       "       17, 16, 22, 14, 14, 19,  7, 11,  5, 12, 24, 16, 17,  3, 16, 19, 24,\n",
       "       14, 18, 22, 11, 22, 22,  4, 11, 20, 15,  1, 22, 11,  1, 21, 16, 17,\n",
       "        1, 16, 15, 15, 16, 24, 15, 16, 16, 16, 17,  6,  0, 20,  1, 14, 15,\n",
       "       14, 12,  9, 24, 11, 24, 16, 13, 18, 12, 20, 12, 11, 11, 16,  8, 23,\n",
       "       24, 22, 20, 21, 16, 24, 19,  8,  8, 16, 16, 15, 13,  9, 24, 21, 21,\n",
       "       16, 12,  3, 10, 17, 15, 14, 18,  8, 20, 17, 16, 14, 22, 15,  2, 16,\n",
       "        9,  0, 12, 18, 21,  0, 17, 22, 16, 22, 17,  9, 22, 16, 17, 24, 18,\n",
       "       14, 21,  1, 20, 15, 13, 13,  1, 17, 15, 23,  1,  3, 12,  0, 15,  3,\n",
       "       24,  4, 18,  5, 22, 22, 20, 16, 22,  1, 10,  5, 16, 16, 15,  1, 16,\n",
       "       22, 15, 14, 20, 16, 20, 18,  0, 11, 21, 14, 21, 19,  6,  4, 19, 21,\n",
       "       22, 10, 10, 22,  9, 19,  7, 21, 21, 12,  6, 17, 13, 19, 21,  8, 13,\n",
       "        9, 21, 13, 21,  1,  1,  5,  9, 24, 15,  8, 15, 21, 16, 12, 22, 24,\n",
       "       10, 21, 13, 19,  0, 20, 15, 20, 19,  1, 21,  6, 17,  0,  0, 17,  0,\n",
       "       21, 22, 14, 18,  6, 14, 24, 17, 17,  3,  4, 21, 16,  6,  0, 11, 12,\n",
       "       11,  9, 15, 13, 11, 16,  0,  0,  0, 17,  5, 15,  9, 10,  5, 20,  1,\n",
       "       24,  6, 20,  1, 13, 15, 20, 20, 15, 16,  1, 10, 15, 19, 11, 22, 13,\n",
       "       21,  0, 21,  5, 16, 20, 17,  1, 20, 15,  6,  2,  6, 14,  0, 20, 21,\n",
       "       22, 22, 16, 17,  5, 13, 22,  2,  2, 20, 19, 21, 22, 11,  1, 14, 16,\n",
       "       20,  0, 22, 22,  8, 20, 19,  2, 15,  7, 16,  1, 12, 10,  4, 24, 17,\n",
       "        9,  8, 20,  0,  0, 16,  6, 13, 16, 16, 13, 20,  0, 24, 16, 10, 21,\n",
       "       14, 19, 15, 20, 16, 14,  6, 15,  2,  1, 16,  6,  1, 13,  8,  7, 17,\n",
       "        8,  0, 21, 22, 17, 15, 16, 16, 21, 15,  1, 20, 18, 11, 22,  5, 14,\n",
       "       16,  9, 23, 13, 16, 15, 19, 24,  8, 21, 21, 24, 15, 24, 15, 13, 22,\n",
       "       16,  0,  1, 15, 20,  3,  5,  5, 21, 15, 16, 21, 22,  9, 22,  5, 10,\n",
       "       15, 15, 13, 15, 22,  5, 21, 21,  0,  1, 13, 13, 21, 24, 21,  5, 14,\n",
       "        1, 21, 24, 21, 21, 22, 10, 10,  6, 24, 21, 17, 17, 20,  9, 11, 22,\n",
       "       16,  2, 16, 24,  6, 16, 10, 16, 13, 21, 21,  0, 17, 16, 19,  8, 15,\n",
       "       20, 21,  9,  0,  3, 22, 17, 24,  6, 21,  6, 20,  0, 16, 21, 22, 17,\n",
       "       20, 13, 23, 15,  2,  0, 20,  5, 20, 24,  1, 15,  0,  7, 22, 13, 12,\n",
       "       10, 15, 20, 24, 13, 17, 19, 20,  5, 16, 15, 14, 11, 14, 20,  2, 20,\n",
       "       16, 24, 14, 20, 14, 14, 20, 21,  8,  0,  8, 21, 11,  0, 22, 21, 11,\n",
       "       17,  5, 19, 14, 21,  2,  0, 19,  5,  4, 18, 10, 22,  5, 15])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 3. Balanced Dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(data2['y_train']),\n",
    "    y=data2['y_train']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.7255813953488373,\n",
       " 1: 0.8,\n",
       " 2: 2.08,\n",
       " 3: 3.466666666666667,\n",
       " 4: 3.9,\n",
       " 5: 1.1555555555555554,\n",
       " 6: 1.7333333333333334,\n",
       " 7: 3.9,\n",
       " 8: 1.95,\n",
       " 9: 1.0064516129032257,\n",
       " 10: 1.6421052631578947,\n",
       " 11: 1.1142857142857143,\n",
       " 12: 1.8352941176470587,\n",
       " 13: 0.9454545454545454,\n",
       " 14: 0.9176470588235294,\n",
       " 15: 0.48,\n",
       " 16: 0.4,\n",
       " 17: 0.7428571428571429,\n",
       " 18: 2.2285714285714286,\n",
       " 19: 1.2,\n",
       " 20: 0.624,\n",
       " 21: 0.4727272727272727,\n",
       " 22: 0.6638297872340425,\n",
       " 23: 3.9,\n",
       " 24: 0.8}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def visualize_class_weights(class_weight_dict):\n",
    "    import matplotlib.pyplot as plt\n",
    "    classes = list(class_weight_dict.keys())\n",
    "    weights = list(class_weight_dict.values())\n",
    "    plt.figure(figsize=(20, 8))  # Adjusted figure size to accommodate all classes\n",
    "    plt.bar(classes, weights, color='skyblue')\n",
    "    plt.title('Distribution of Class Weights')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Weights')\n",
    "    plt.xticks(rotation=45)  # Rotated x-axis labels for better readability\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "visualize_class_weights(class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline \u001b[38;5;28;01mas\u001b[39;00m ImbPipeline\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader, WeightedRandomSampler\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "## PYTORCH IMPLEMENTATION ##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class ImbalancedTextDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 texts: List[str],\n",
    "                 labels: List[int],\n",
    "                 tokenizer_name: str = \"bert-base-uncased\",\n",
    "                 max_length: int = 512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(label)\n",
    "        }\n",
    "\n",
    "class ImbalancedDataHandler:\n",
    "    def __init__(self, \n",
    "                 strategy: str = \"weighted\",  # \"weighted\", \"oversample\", \"undersample\", \"smote\"\n",
    "                 tokenizer_name: str = \"bert-base-uncased\",\n",
    "                 max_length: int = 512,\n",
    "                 batch_size: int = 32):\n",
    "        self.strategy = strategy\n",
    "        self.tokenizer_name = tokenizer_name\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def get_class_weights(self, labels: List[int]) -> torch.Tensor:\n",
    "        \"\"\"Calculate class weights inversely proportional to class frequencies.\"\"\"\n",
    "        class_counts = Counter(labels)\n",
    "        total = len(labels)\n",
    "        weights = {cls: total / count for cls, count in class_counts.items()}\n",
    "        \n",
    "        # Normalize weights\n",
    "        weight_sum = sum(weights.values())\n",
    "        weights = {cls: weight / weight_sum for cls, weight in weights.items()}\n",
    "        \n",
    "        return torch.tensor([weights[i] for i in range(len(class_counts))])\n",
    "    \n",
    "    def get_sample_weights(self, labels: List[int]) -> torch.Tensor:\n",
    "        \"\"\"Calculate sample weights based on class frequencies.\"\"\"\n",
    "        class_weights = self.get_class_weights(labels)\n",
    "        return torch.tensor([class_weights[label] for label in labels])\n",
    "    \n",
    "    def oversample(self, texts: List[str], labels: List[int]) -> Tuple[List[str], List[int]]:\n",
    "        \"\"\"Oversample minority classes to match majority class.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        majority_size = max(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) < majority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=True,\n",
    "                                   n_samples=majority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "    \n",
    "    def undersample(self, texts: List[str], labels: List[int]) -> Tuple[List[str], List[int]]:\n",
    "        \"\"\"Undersample majority classes to match minority class.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        minority_size = min(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) > minority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=False,\n",
    "                                   n_samples=minority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "    \n",
    "    def create_dataloader(self, texts: List[str], labels: List[int], shuffle: bool = True) -> DataLoader:\n",
    "        \"\"\"Create DataLoader with appropriate sampling strategy.\"\"\"\n",
    "        dataset = ImbalancedTextDataset(texts, labels, self.tokenizer_name, self.max_length)\n",
    "        \n",
    "        if self.strategy == \"weighted\":\n",
    "            # Use WeightedRandomSampler\n",
    "            sample_weights = self.get_sample_weights(labels)\n",
    "            sampler = WeightedRandomSampler(\n",
    "                weights=sample_weights,\n",
    "                num_samples=len(sample_weights),\n",
    "                replacement=True\n",
    "            )\n",
    "            return DataLoader(dataset, batch_size=self.batch_size, sampler=sampler)\n",
    "        \n",
    "        elif self.strategy == \"oversample\":\n",
    "            # Oversample minority classes\n",
    "            balanced_texts, balanced_labels = self.oversample(texts, labels)\n",
    "            balanced_dataset = ImbalancedTextDataset(\n",
    "                balanced_texts, \n",
    "                balanced_labels,\n",
    "                self.tokenizer_name,\n",
    "                self.max_length\n",
    "            )\n",
    "            return DataLoader(balanced_dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
    "        \n",
    "        elif self.strategy == \"undersample\":\n",
    "            # Undersample majority classes\n",
    "            balanced_texts, balanced_labels = self.undersample(texts, labels)\n",
    "            balanced_dataset = ImbalancedTextDataset(\n",
    "                balanced_texts,\n",
    "                balanced_labels,\n",
    "                self.tokenizer_name,\n",
    "                self.max_length\n",
    "            )\n",
    "            return DataLoader(balanced_dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
    "        \n",
    "        else:\n",
    "            # No balancing, just return regular DataLoader\n",
    "            return DataLoader(dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
    "    \n",
    "    def get_class_distribution(self, labels: List[int]) -> Dict[int, float]:\n",
    "        \"\"\"Calculate class distribution percentages.\"\"\"\n",
    "        total = len(labels)\n",
    "        class_counts = Counter(labels)\n",
    "        return {label: count/total * 100 for label, count in class_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, TFAutoModel\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTFTextDataset\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     15\u001b[0m                  texts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m     16\u001b[0m                  labels: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m     17\u001b[0m                  tokenizer_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m                  max_length: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m     19\u001b[0m                  batch_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "## TENSORFLOW INMPLENTATION\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "class TFTextDataset:\n",
    "    def __init__(self,\n",
    "                 texts: List[str],\n",
    "                 labels: List[int],\n",
    "                 tokenizer_name: str = \"bert-base-uncased\",\n",
    "                 max_length: int = 512,\n",
    "                 batch_size: int = 32):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def encode_texts(self) -> Dict[str, tf.Tensor]:\n",
    "        \"\"\"Encode texts using the tokenizer.\"\"\"\n",
    "        encodings = self.tokenizer(\n",
    "            self.texts,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"tf\"\n",
    "        )\n",
    "        return encodings\n",
    "    \n",
    "    def create_dataset(self, shuffle: bool = True) -> tf.data.Dataset:\n",
    "        \"\"\"Create TensorFlow dataset.\"\"\"\n",
    "        encodings = self.encode_texts()\n",
    "        labels_tensor = tf.convert_to_tensor(self.labels)\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            {\n",
    "                'input_ids': encodings['input_ids'],\n",
    "                'attention_mask': encodings['attention_mask']\n",
    "            },\n",
    "            labels_tensor\n",
    "        ))\n",
    "        \n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=len(self.texts))\n",
    "            \n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        return dataset\n",
    "\n",
    "class TFImbalancedDataHandler:\n",
    "    def __init__(self,\n",
    "                 strategy: str = \"weighted\",  # \"weighted\", \"oversample\", \"undersample\"\n",
    "                 tokenizer_name: str = \"bert-base-uncased\",\n",
    "                 max_length: int = 512,\n",
    "                 batch_size: int = 32):\n",
    "        self.strategy = strategy\n",
    "        self.tokenizer_name = tokenizer_name\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def calculate_class_weights(self, labels: List[int]) -> Dict[int, float]:\n",
    "        \"\"\"Calculate class weights inversely proportional to class frequencies.\"\"\"\n",
    "        class_counts = Counter(labels)\n",
    "        total = len(labels)\n",
    "        weights = {cls: total / count for cls, count in class_counts.items()}\n",
    "        \n",
    "        # Normalize weights\n",
    "        weight_sum = sum(weights.values())\n",
    "        weights = {cls: weight / weight_sum for cls, weight in weights.items()}\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def oversample(self, texts: List[str], labels: List[int]) -> Tuple[List[str], List[int]]:\n",
    "        \"\"\"Oversample minority classes to match majority class.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        majority_size = max(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) < majority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=True,\n",
    "                                   n_samples=majority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "    \n",
    "    def undersample(self, texts: List[str], labels: List[int]) -> Tuple[List[str], List[int]]:\n",
    "        \"\"\"Undersample majority classes to match minority class.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        minority_size = min(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) > minority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=False,\n",
    "                                   n_samples=minority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "    \n",
    "    def create_dataset(self, texts: List[str], labels: List[int]) -> Union[tf.data.Dataset, Tuple[tf.data.Dataset, Dict]]:\n",
    "        \"\"\"Create TensorFlow dataset with appropriate balancing strategy.\"\"\"\n",
    "        if self.strategy == \"weighted\":\n",
    "            # Create dataset with class weights\n",
    "            dataset = TFTextDataset(\n",
    "                texts,\n",
    "                labels,\n",
    "                self.tokenizer_name,\n",
    "                self.max_length,\n",
    "                self.batch_size\n",
    "            ).create_dataset()\n",
    "            \n",
    "            class_weights = self.calculate_class_weights(labels)\n",
    "            return dataset, class_weights\n",
    "        \n",
    "        elif self.strategy == \"oversample\":\n",
    "            # Oversample minority classes\n",
    "            balanced_texts, balanced_labels = self.oversample(texts, labels)\n",
    "            dataset = TFTextDataset(\n",
    "                balanced_texts,\n",
    "                balanced_labels,\n",
    "                self.tokenizer_name,\n",
    "                self.max_length,\n",
    "                self.batch_size\n",
    "            ).create_dataset()\n",
    "            return dataset\n",
    "        \n",
    "        elif self.strategy == \"undersample\":\n",
    "            # Undersample majority classes\n",
    "            balanced_texts, balanced_labels = self.undersample(texts, labels)\n",
    "            dataset = TFTextDataset(\n",
    "                balanced_texts,\n",
    "                balanced_labels,\n",
    "                self.tokenizer_name,\n",
    "                self.max_length,\n",
    "                self.batch_size\n",
    "            ).create_dataset()\n",
    "            return dataset\n",
    "        \n",
    "        else:\n",
    "            # No balancing\n",
    "            dataset = TFTextDataset(\n",
    "                texts,\n",
    "                labels,\n",
    "                self.tokenizer_name,\n",
    "                self.max_length,\n",
    "                self.batch_size\n",
    "            ).create_dataset()\n",
    "            return dataset\n",
    "    \n",
    "    def get_class_distribution(self, labels: List[int]) -> Dict[int, float]:\n",
    "        \"\"\"Calculate class distribution percentages.\"\"\"\n",
    "        total = len(labels)\n",
    "        class_counts = Counter(labels)\n",
    "        return {label: count/total * 100 for label, count in class_counts.items()}\n",
    "\n",
    "# Example model definition using TensorFlow\n",
    "class TextClassificationModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes: int, model_name: str = \"bert-base-uncased\"):\n",
    "        super().__init__()\n",
    "        self.bert = TFAutoModel.from_pretrained(model_name)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        # Get BERT outputs\n",
    "        bert_outputs = self.bert(inputs['input_ids'], \n",
    "                               attention_mask=inputs['attention_mask'],\n",
    "                               training=training)\n",
    "        \n",
    "        # Use [CLS] token output\n",
    "        pooled_output = bert_outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        \n",
    "        # Classify\n",
    "        return self.classifier(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILIZING EXISITING PREPROCESSOR\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "\n",
    "class ImbalancedNLPHandler:\n",
    "    def __init__(self,\n",
    "                 preprocessor: NLPPreprocessor,\n",
    "                 strategy: str = \"weighted\"):\n",
    "        \"\"\"\n",
    "        Combines NLPPreprocessor with imbalanced data handling.\n",
    "        \n",
    "        Args:\n",
    "            preprocessor: Existing NLPPreprocessor instance\n",
    "            strategy: \"weighted\", \"oversample\", or \"undersample\"\n",
    "        \"\"\"\n",
    "        self.preprocessor = preprocessor\n",
    "        self.strategy = strategy\n",
    "    \n",
    "    def calculate_class_weights(self, labels: List) -> Dict:\n",
    "        \"\"\"Calculate class weights for imbalanced data.\"\"\"\n",
    "        class_counts = Counter(labels)\n",
    "        total = len(labels)\n",
    "        weights = {cls: total / count for cls, count in class_counts.items()}\n",
    "        \n",
    "        # Normalize weights\n",
    "        weight_sum = sum(weights.values())\n",
    "        weights = {cls: weight / weight_sum for cls, weight in weights.items()}\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def oversample(self, texts: List[str], labels: List) -> Tuple[List[str], List]:\n",
    "        \"\"\"Oversample minority classes.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        majority_size = max(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) < majority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=True,\n",
    "                                   n_samples=majority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "    \n",
    "    def undersample(self, texts: List[str], labels: List) -> Tuple[List[str], List]:\n",
    "        \"\"\"Undersample majority classes.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        minority_size = min(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) > minority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=False,\n",
    "                                   n_samples=minority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "\n",
    "    def prepare_balanced_data(self, texts: List[str], labels: List, use_word2vec: bool = False):\n",
    "        \"\"\"Prepare data with imbalance handling.\"\"\"\n",
    "        # Apply balancing strategy if needed\n",
    "        if self.strategy == \"oversample\":\n",
    "            texts, labels = self.oversample(texts, labels)\n",
    "        elif self.strategy == \"undersample\":\n",
    "            texts, labels = self.undersample(texts, labels)\n",
    "        \n",
    "        # Use existing preprocessor to prepare data\n",
    "        data = self.preprocessor.prepare_data(texts, labels, use_word2vec)\n",
    "        \n",
    "        # Add class weights if using weighted strategy\n",
    "        if self.strategy == \"weighted\":\n",
    "            class_weights = self.calculate_class_weights(labels)\n",
    "            data['class_weights'] = class_weights\n",
    "            \n",
    "            # Update datasets to use sample weights\n",
    "            weights = [class_weights[label] for label in data['y_train']]\n",
    "            data['train_dataset'] = tf.data.Dataset.from_tensor_slices(\n",
    "                (data['X_train'], data['y_train'], weights)\n",
    "            ).shuffle(10000).batch(32)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def get_class_distribution(self, labels: List) -> Dict:\n",
    "        \"\"\"Calculate class distribution percentages.\"\"\"\n",
    "        total = len(labels)\n",
    "        class_counts = Counter(labels)\n",
    "        return {label: count/total * 100 for label, count in class_counts.items()}\n",
    "\n",
    "# Example custom model that can use the preprocessor's word2vec embeddings\n",
    "class CustomTextClassifier(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = tf.keras.layers.Embedding(\n",
    "                vocab_size, embedding_dim,\n",
    "                weights=[embedding_matrix],\n",
    "                trainable=False\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "            \n",
    "        self.lstm = tf.keras.layers.LSTM(64)\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.lstm(x)\n",
    "        x = self.dense1(x)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found potentially problematic words:\n",
      "Problem word: ntp\n",
      "Problem word: ntp\n",
      "Found potentially problematic words:\n",
      "Problem word: npc\n",
      "Found potentially problematic words:\n",
      "Problem word: nac\n",
      "Problem word: nac\n"
     ]
    }
   ],
   "source": [
    "data['cleaned_text'] = data['Resume'].apply(ResumeTextPreprocessor().process_and_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "      <td>john smith phone box callahan greatresumesfast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "      <td>ame surname address mobile email personal prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "      <td>anthony brown assistant area expertise persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "      <td>www downloadmela com satheesh email career obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "      <td>human resource director expert organizational ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b\"Free Flight Attendant Resume\\nDarlene Flint\\...</td>\n",
       "      <td>free flight attendant resume darlene flint wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Corporate Flight Attendant Resume\\nCAITLIN F...</td>\n",
       "      <td>corporate flight attendant resume caitlin flan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...</td>\n",
       "      <td>major conrad preedom fairchild suite usaf acad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...</td>\n",
       "      <td>stacy sample cell email com qualification flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Entry Level Resume Guide\\n\\nThis packet is i...</td>\n",
       "      <td>entry level resume guide packet intended serve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Category                                             Resume  \\\n",
       "0        1        HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...   \n",
       "1        2        HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...   \n",
       "2        3        HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...   \n",
       "3        4        HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...   \n",
       "4        5        HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...   \n",
       "...    ...       ...                                                ...   \n",
       "1214  1215  Aviation  b\"Free Flight Attendant Resume\\nDarlene Flint\\...   \n",
       "1215  1216  Aviation  b'Corporate Flight Attendant Resume\\nCAITLIN F...   \n",
       "1216  1217  Aviation  b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...   \n",
       "1217  1218  Aviation  b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...   \n",
       "1218  1219  Aviation  b'Entry Level Resume Guide\\n\\nThis packet is i...   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0     john smith phone box callahan greatresumesfast...  \n",
       "1     ame surname address mobile email personal prof...  \n",
       "2     anthony brown assistant area expertise persona...  \n",
       "3     www downloadmela com satheesh email career obj...  \n",
       "4     human resource director expert organizational ...  \n",
       "...                                                 ...  \n",
       "1214  free flight attendant resume darlene flint wes...  \n",
       "1215  corporate flight attendant resume caitlin flan...  \n",
       "1216  major conrad preedom fairchild suite usaf acad...  \n",
       "1217  stacy sample cell email com qualification flig...  \n",
       "1218  entry level resume guide packet intended serve...  \n",
       "\n",
       "[1219 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing text characteristics...\n",
      "Average length: 607.49\n",
      "Median length: 317.00\n",
      "95th percentile length: 2605.00\n",
      "Max length: 6149\n",
      "Total unique words: 32427\n",
      "Words appearing only once: 12713\n",
      "Tokenizing texts...\n",
      "Creating Word2Vec embeddings...\n",
      "Splitting data...\n",
      "Creating TF datasets...\n"
     ]
    }
   ],
   "source": [
    "# Initialize your existing preprocessor\n",
    "preprocessor = NLPPreprocessor(\n",
    "    max_Swords=10000,\n",
    "    max_length=500,\n",
    "    embedding_dim=100\n",
    ")\n",
    "\n",
    "# Using your preprocessor\n",
    "preprocessor = NLPPreprocessor(max_words=10000, max_length=500, embedding_dim=100)\n",
    "data2 = preprocessor.prepare_data(\n",
    "    texts=data['cleaned_text'],\n",
    "    labels=data['Category'],\n",
    "    use_word2vec=True  # Use Word2Vec embeddings\n",
    ")\n",
    "# data2\n",
    "\n",
    "if data2['embedding_matrix'] is not None:\n",
    "        vocab_size = data2['embedding_matrix'].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class distribution: {14: 4.358974358974359, 15: 8.333333333333332, 16: 10.0, 24: 5.0, 23: 1.0256410256410255, 21: 8.461538461538462, 1: 5.0, 11: 3.5897435897435894, 5: 3.4615384615384617, 0: 5.512820512820513, 20: 6.41025641025641, 10: 2.435897435897436, 4: 1.0256410256410255, 7: 1.0256410256410255, 22: 6.0256410256410255, 9: 3.974358974358974, 19: 3.3333333333333335, 17: 5.384615384615385, 13: 4.230769230769231, 2: 1.9230769230769231, 18: 1.7948717948717947, 6: 2.307692307692308, 12: 2.1794871794871793, 3: 1.153846153846154, 8: 2.051282051282051}\n"
     ]
    }
   ],
   "source": [
    "# Create the imbalanced handler with your preprocessor\n",
    "handler = ImbalancedNLPHandler(\n",
    "    preprocessor=preprocessor,\n",
    "    strategy=\"weighted\"  # or \"oversample\" or \"undersample\"\n",
    ")\n",
    "\n",
    "# Check initial class distribution\n",
    "initial_dist = handler.get_class_distribution(data2[\"y_train\"])\n",
    "print(\"Initial class distribution:\", initial_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing text characteristics...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare data with imbalance handling\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_balanced_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_word2vec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 86\u001b[0m, in \u001b[0;36mImbalancedNLPHandler.prepare_balanced_data\u001b[1;34m(self, texts, labels, use_word2vec)\u001b[0m\n\u001b[0;32m     83\u001b[0m     texts, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mundersample(texts, labels)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Use existing preprocessor to prepare data\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_word2vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Add class weights if using weighted strategy\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Projs\\COde\\ResAnalysis\\Resume-Analysis-NLP\\src\\preprocessing\\data_preprocessing.py:272\u001b[0m, in \u001b[0;36mNLPPreprocessor.prepare_data\u001b[1;34m(self, texts, labels, use_word2vec)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# Analyze text characteristics\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyzing text characteristics...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_text_lengths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyze_vocabulary(texts)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# Fit tokenizer on texts\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projs\\COde\\ResAnalysis\\Resume-Analysis-NLP\\src\\preprocessing\\data_preprocessing.py:229\u001b[0m, in \u001b[0;36mNLPPreprocessor.analyze_text_lengths\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_text_lengths\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts):\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Analyze text lengths to help determine optimal max_length\"\"\"\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(lengths)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedian length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmedian(lengths)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Projs\\COde\\ResAnalysis\\Resume-Analysis-NLP\\src\\preprocessing\\data_preprocessing.py:229\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_text_lengths\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts):\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Analyze text lengths to help determine optimal max_length\"\"\"\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(lengths)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedian length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmedian(lengths)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Prepare data with imbalance handling\n",
    "data = handler.prepare_balanced_data(data2[\"X_train\"], data2[\"X_train\"], use_word2vec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
