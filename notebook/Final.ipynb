{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text data...\n",
      "Found potentially problematic words:\n",
      "Problem word: ntp\n",
      "Problem word: ntp\n",
      "Found potentially problematic words:\n",
      "Problem word: npc\n",
      "Found potentially problematic words:\n",
      "Problem word: nac\n",
      "Problem word: nac\n",
      "Tokenizing text...\n",
      "Splitting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projs\\COde\\ResAnalysis\\resanalysis\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# Append the parent directory to the system path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from src.preprocessing.data_preprocessing import ResumeTextPreprocessor, NLPPreprocessor, ImbalancedNLPHandler\n",
    "from src.training.training import call_data, create_and_compile_model\n",
    "from src.model.model import TextAnalysisModel2, TextClassifier\n",
    "\n",
    "from src.utils.helpers import plot_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b\"Free Flight Attendant Resume\\nDarlene Flint\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Corporate Flight Attendant Resume\\nCAITLIN F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Entry Level Resume Guide\\n\\nThis packet is i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Category                                             Resume\n",
       "0        1        HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...\n",
       "1        2        HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...\n",
       "2        3        HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...\n",
       "3        4        HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...\n",
       "4        5        HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...\n",
       "...    ...       ...                                                ...\n",
       "1214  1215  Aviation  b\"Free Flight Attendant Resume\\nDarlene Flint\\...\n",
       "1215  1216  Aviation  b'Corporate Flight Attendant Resume\\nCAITLIN F...\n",
       "1216  1217  Aviation  b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...\n",
       "1217  1218  Aviation  b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...\n",
       "1218  1219  Aviation  b'Entry Level Resume Guide\\n\\nThis packet is i...\n",
       "\n",
       "[1219 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = call_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILIZING EXISITING PREPROCESSOR\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "\n",
    "class ImbalancedNLPHandler:\n",
    "    def __init__(self,\n",
    "                 preprocessor: NLPPreprocessor,\n",
    "                 strategy: str = \"weighted\"):\n",
    "        \"\"\"\n",
    "        Combines NLPPreprocessor with imbalanced data handling.\n",
    "        \n",
    "        Args:\n",
    "            preprocessor: Existing NLPPreprocessor instance\n",
    "            strategy: \"weighted\", \"oversample\", or \"undersample\"\n",
    "        \"\"\"\n",
    "        self.preprocessor = preprocessor\n",
    "        self.strategy = strategy\n",
    "    \n",
    "    def calculate_class_weights(self, labels: List) -> Dict:\n",
    "        \"\"\"Calculate class weights for imbalanced data.\"\"\"\n",
    "        class_counts = Counter(labels)\n",
    "        total = len(labels)\n",
    "        weights = {cls: total / count for cls, count in class_counts.items()}\n",
    "        \n",
    "        # Normalize weights\n",
    "        weight_sum = sum(weights.values())\n",
    "        weights = {cls: weight / weight_sum for cls, weight in weights.items()}\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def oversample(self, texts: List[str], labels: List) -> Tuple[List[str], List]:\n",
    "        \"\"\"Oversample minority classes.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        majority_size = max(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) < majority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=True,\n",
    "                                   n_samples=majority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "    \n",
    "    def undersample(self, texts: List[str], labels: List) -> Tuple[List[str], List]:\n",
    "        \"\"\"Undersample majority classes.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        minority_size = min(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) > minority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=False,\n",
    "                                   n_samples=minority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "\n",
    "    def prepare_balanced_data(self, texts: List[str], labels: List, use_word2vec: bool = False):\n",
    "        \"\"\"Prepare data with imbalance handling.\"\"\"\n",
    "        # Apply balancing strategy if needed\n",
    "        if self.strategy == \"oversample\":\n",
    "            texts, labels = self.oversample(texts, labels)\n",
    "        elif self.strategy == \"undersample\":\n",
    "            texts, labels = self.undersample(texts, labels)\n",
    "        \n",
    "        # Use existing preprocessor to prepare data\n",
    "        data = self.preprocessor.prepare_data(texts, labels, use_word2vec)\n",
    "        \n",
    "        # Add class weights if using weighted strategy\n",
    "        if self.strategy == \"weighted\":\n",
    "            class_weights = self.calculate_class_weights(data['y_train'])\n",
    "            data['class_weights'] = class_weights\n",
    "            \n",
    "            # Update datasets to use sample weights\n",
    "            weights = [class_weights[label] for label in data['y_train']]\n",
    "            data['train_dataset'] = tf.data.Dataset.from_tensor_slices(\n",
    "                (data['X_train'], data['y_train'], weights)\n",
    "            ).shuffle(10000).batch(32)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def get_class_distribution(self, labels: List) -> Dict:\n",
    "        \"\"\"Calculate class distribution percentages.\"\"\"\n",
    "        total = len(labels)\n",
    "        class_counts = Counter(labels)\n",
    "        return {label: count/total * 100 for label, count in class_counts.items()}\n",
    "\n",
    "# Example custom model that can use the preprocessor's word2vec embeddings\n",
    "class CustomTextClassifier(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = tf.keras.layers.Embedding(\n",
    "                vocab_size, embedding_dim,\n",
    "                weights=[embedding_matrix],\n",
    "                trainable=False\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "            \n",
    "        self.lstm = tf.keras.layers.LSTM(64)\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.lstm(x)\n",
    "        x = self.dense1(x)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b\"Free Flight Attendant Resume\\nDarlene Flint\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Corporate Flight Attendant Resume\\nCAITLIN F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Entry Level Resume Guide\\n\\nThis packet is i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Category                                             Resume\n",
       "0        1        HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...\n",
       "1        2        HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...\n",
       "2        3        HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...\n",
       "3        4        HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...\n",
       "4        5        HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...\n",
       "...    ...       ...                                                ...\n",
       "1214  1215  Aviation  b\"Free Flight Attendant Resume\\nDarlene Flint\\...\n",
       "1215  1216  Aviation  b'Corporate Flight Attendant Resume\\nCAITLIN F...\n",
       "1216  1217  Aviation  b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...\n",
       "1217  1218  Aviation  b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...\n",
       "1218  1219  Aviation  b'Entry Level Resume Guide\\n\\nThis packet is i...\n",
       "\n",
       "[1219 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found potentially problematic words:\n",
      "Problem word: ntp\n",
      "Problem word: ntp\n",
      "Found potentially problematic words:\n",
      "Problem word: npc\n",
      "Found potentially problematic words:\n",
      "Problem word: nac\n",
      "Problem word: nac\n",
      "Analyzing text characteristics...\n",
      "Average length: 607.49\n",
      "Median length: 317.00\n",
      "95th percentile length: 2605.00\n",
      "Max length: 6149\n",
      "Total unique words: 32427\n",
      "Words appearing only once: 12713\n",
      "Tokenizing texts...\n",
      "Creating Word2Vec embeddings...\n",
      "Splitting data...\n",
      "Creating TF datasets...\n"
     ]
    }
   ],
   "source": [
    "data['cleaned_text'] = data['Resume'].apply(ResumeTextPreprocessor().process_and_check)\n",
    "\n",
    "# # Initialize your existing preprocessor\n",
    "# preprocessor = NLPPreprocessor(\n",
    "#     max_words=10000,\n",
    "#     max_length=500,\n",
    "#     embedding_dim=100\n",
    "# )\n",
    "\n",
    "# Using your preprocessor\n",
    "preprocessor = NLPPreprocessor(\n",
    "    max_words=10000,\n",
    "    max_length=500,\n",
    "    embedding_dim=100,\n",
    "    TFDataset=True\n",
    ")\n",
    "data_imbal = preprocessor.prepare_data(\n",
    "    texts=data['cleaned_text'],\n",
    "    labels=data['Category'],\n",
    "    use_word2vec=True  # Use Word2Vec embeddings\n",
    ")\n",
    "# data2\n",
    "\n",
    "if data_imbal['embedding_matrix'] is not None:\n",
    "        vocab_size = data_imbal['embedding_matrix'].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class distribution: {'HR': 3.3634126333059884, 'Designing': 4.1837571780147655, 'Managment': 6.070549630844955, 'Information Technology': 8.531583264971287, 'Education': 8.367514356029531, 'Advocate': 5.004101722723544, 'Business Development': 3.6095159967186223, 'Health & Fitness': 6.316652994257588, 'Agricultural': 1.9688269073010665, 'BPO': 2.0508613617719442, 'Sales': 5.004101722723544, 'Consultant': 2.1328958162428218, 'Digital Media': 4.4298605414273995, 'Automobile': 2.2149302707136997, 'Food & Beverages': 1.8047579983593112, 'Finance': 5.414273995077933, 'Apparel': 1.1484823625922889, 'Engineering': 9.92616899097621, 'Accountant': 5.496308449548811, 'Building & Construction': 2.3789991796554553, 'Architects': 0.9844134536505332, 'Public Relations': 1.0664479081214109, 'Banking': 3.937653814602133, 'Arts': 3.5274815422477444, 'Aviation': 1.0664479081214109}\n"
     ]
    }
   ],
   "source": [
    "# Create the imbalanced handler with your preprocessor\n",
    "handler = ImbalancedNLPHandler(\n",
    "    preprocessor=preprocessor,\n",
    "    strategy=\"weighted\"  # or \"oversample\" or \"undersample\"\n",
    ")\n",
    "\n",
    "# Check initial class distribution\n",
    "initial_dist = handler.get_class_distribution(data[\"Category\"])\n",
    "print(\"Initial class distribution:\", initial_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing text characteristics...\n",
      "Average length: 607.49\n",
      "Median length: 317.00\n",
      "95th percentile length: 2605.00\n",
      "Max length: 6149\n",
      "Total unique words: 32427\n",
      "Words appearing only once: 12713\n",
      "Tokenizing texts...\n",
      "Creating Word2Vec embeddings...\n",
      "Splitting data...\n",
      "Creating TF datasets...\n"
     ]
    }
   ],
   "source": [
    "# Prepare data with imbalance handling\n",
    "data = handler.prepare_balanced_data(data[\"cleaned_text\"], data[\"Category\"], use_word2vec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.023721396388699953,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.10081593465197479,\n",
       " 0.023721396388699953,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.028804552757707085,\n",
       " 0.012408115034089204,\n",
       " 0.02987138804502957,\n",
       " 0.018756452958506937,\n",
       " 0.01222011329114846,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.042448814590305174,\n",
       " 0.010340095861741004,\n",
       " 0.10081593465197479,\n",
       " 0.010340095861741004,\n",
       " 0.10081593465197479,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.028804552757707085,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.012408115034089204,\n",
       " 0.02601701539405801,\n",
       " 0.02601701539405801,\n",
       " 0.031020287585223013,\n",
       " 0.023721396388699953,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.018756452958506937,\n",
       " 0.02987138804502957,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.02601701539405801,\n",
       " 0.02601701539405801,\n",
       " 0.031020287585223013,\n",
       " 0.019203035171804723,\n",
       " 0.01222011329114846,\n",
       " 0.02444022658229692,\n",
       " 0.028804552757707085,\n",
       " 0.02601701539405801,\n",
       " 0.017160159089697837,\n",
       " 0.02601701539405801,\n",
       " 0.01222011329114846,\n",
       " 0.031020287585223013,\n",
       " 0.05376849848105322,\n",
       " 0.02444022658229692,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.031020287585223013,\n",
       " 0.023721396388699953,\n",
       " 0.018756452958506937,\n",
       " 0.02601701539405801,\n",
       " 0.10081593465197479,\n",
       " 0.023721396388699953,\n",
       " 0.018756452958506937,\n",
       " 0.028804552757707085,\n",
       " 0.02444022658229692,\n",
       " 0.05376849848105322,\n",
       " 0.02601701539405801,\n",
       " 0.017160159089697837,\n",
       " 0.016130549544315965,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.019203035171804723,\n",
       " 0.031020287585223013,\n",
       " 0.10081593465197479,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.018756452958506937,\n",
       " 0.10081593465197479,\n",
       " 0.031020287585223013,\n",
       " 0.02601701539405801,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.019203035171804723,\n",
       " 0.016130549544315965,\n",
       " 0.05760910551541417,\n",
       " 0.02987138804502957,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.023721396388699953,\n",
       " 0.017160159089697837,\n",
       " 0.04480708206754436,\n",
       " 0.01222011329114846,\n",
       " 0.10081593465197479,\n",
       " 0.019203035171804723,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.047442792777399906,\n",
       " 0.031020287585223013,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.05760910551541417,\n",
       " 0.017160159089697837,\n",
       " 0.05760910551541417,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.028804552757707085,\n",
       " 0.012408115034089204,\n",
       " 0.028804552757707085,\n",
       " 0.042448814590305174,\n",
       " 0.019203035171804723,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.019203035171804723,\n",
       " 0.02987138804502957,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.02444022658229692,\n",
       " 0.018756452958506937,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.05760910551541417,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.016130549544315965,\n",
       " 0.028804552757707085,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.018756452958506937,\n",
       " 0.10081593465197479,\n",
       " 0.047442792777399906,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.02987138804502957,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.04480708206754436,\n",
       " 0.08961416413508871,\n",
       " 0.01222011329114846,\n",
       " 0.02601701539405801,\n",
       " 0.047442792777399906,\n",
       " 0.016130549544315965,\n",
       " 0.050407967325987395,\n",
       " 0.020680191723482007,\n",
       " 0.050407967325987395,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.05376849848105322,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.05376849848105322,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.017160159089697837,\n",
       " 0.02601701539405801,\n",
       " 0.010340095861741004,\n",
       " 0.05376849848105322,\n",
       " 0.028804552757707085,\n",
       " 0.020680191723482007,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.018756452958506937,\n",
       " 0.031020287585223013,\n",
       " 0.023721396388699953,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.017160159089697837,\n",
       " 0.023721396388699953,\n",
       " 0.018756452958506937,\n",
       " 0.02987138804502957,\n",
       " 0.047442792777399906,\n",
       " 0.020680191723482007,\n",
       " 0.028804552757707085,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.02601701539405801,\n",
       " 0.028804552757707085,\n",
       " 0.012408115034089204,\n",
       " 0.019203035171804723,\n",
       " 0.047442792777399906,\n",
       " 0.02601701539405801,\n",
       " 0.023721396388699953,\n",
       " 0.010340095861741004,\n",
       " 0.042448814590305174,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.02601701539405801,\n",
       " 0.08961416413508871,\n",
       " 0.02444022658229692,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.02444022658229692,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.012408115034089204,\n",
       " 0.02987138804502957,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.042448814590305174,\n",
       " 0.01222011329114846,\n",
       " 0.10081593465197479,\n",
       " 0.019203035171804723,\n",
       " 0.010340095861741004,\n",
       " 0.017160159089697837,\n",
       " 0.023721396388699953,\n",
       " 0.023721396388699953,\n",
       " 0.031020287585223013,\n",
       " 0.10081593465197479,\n",
       " 0.028804552757707085,\n",
       " 0.02987138804502957,\n",
       " 0.047442792777399906,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.08961416413508871,\n",
       " 0.010340095861741004,\n",
       " 0.031020287585223013,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.05760910551541417,\n",
       " 0.017160159089697837,\n",
       " 0.028804552757707085,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.10081593465197479,\n",
       " 0.028804552757707085,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.017160159089697837,\n",
       " 0.028804552757707085,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.04480708206754436,\n",
       " 0.018756452958506937,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.012408115034089204,\n",
       " 0.023721396388699953,\n",
       " 0.047442792777399906,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.028804552757707085,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.02444022658229692,\n",
       " 0.05760910551541417,\n",
       " 0.047442792777399906,\n",
       " 0.016130549544315965,\n",
       " 0.047442792777399906,\n",
       " 0.028804552757707085,\n",
       " 0.028804552757707085,\n",
       " 0.010340095861741004,\n",
       " 0.050407967325987395,\n",
       " 0.10081593465197479,\n",
       " 0.020680191723482007,\n",
       " 0.017160159089697837,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.031020287585223013,\n",
       " 0.050407967325987395,\n",
       " 0.050407967325987395,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.047442792777399906,\n",
       " 0.08961416413508871,\n",
       " 0.042448814590305174,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.023721396388699953,\n",
       " 0.05760910551541417,\n",
       " 0.050407967325987395,\n",
       " 0.016130549544315965,\n",
       " 0.019203035171804723,\n",
       " 0.010340095861741004,\n",
       " 0.023721396388699953,\n",
       " 0.017160159089697837,\n",
       " 0.012408115034089204,\n",
       " 0.05376849848105322,\n",
       " 0.010340095861741004,\n",
       " 0.02601701539405801,\n",
       " 0.018756452958506937,\n",
       " 0.047442792777399906,\n",
       " 0.05760910551541417,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.019203035171804723,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.017160159089697837,\n",
       " 0.019203035171804723,\n",
       " 0.02601701539405801,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.05760910551541417,\n",
       " 0.023721396388699953,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.02444022658229692,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.10081593465197479,\n",
       " 0.020680191723482007,\n",
       " 0.08961416413508871,\n",
       " 0.047442792777399906,\n",
       " 0.018756452958506937,\n",
       " 0.012408115034089204,\n",
       " 0.08961416413508871,\n",
       " 0.020680191723482007,\n",
       " 0.10081593465197479,\n",
       " 0.05760910551541417,\n",
       " 0.02987138804502957,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.017160159089697837,\n",
       " 0.020680191723482007,\n",
       " 0.042448814590305174,\n",
       " 0.02987138804502957,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.017160159089697837,\n",
       " 0.012408115034089204,\n",
       " 0.023721396388699953,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.016130549544315965,\n",
       " 0.05760910551541417,\n",
       " 0.018756452958506937,\n",
       " 0.028804552757707085,\n",
       " 0.01222011329114846,\n",
       " 0.023721396388699953,\n",
       " 0.01222011329114846,\n",
       " 0.031020287585223013,\n",
       " 0.04480708206754436,\n",
       " 0.10081593465197479,\n",
       " 0.031020287585223013,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.042448814590305174,\n",
       " 0.042448814590305174,\n",
       " 0.017160159089697837,\n",
       " 0.02601701539405801,\n",
       " 0.031020287585223013,\n",
       " 0.10081593465197479,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.047442792777399906,\n",
       " 0.04480708206754436,\n",
       " 0.019203035171804723,\n",
       " 0.02444022658229692,\n",
       " 0.031020287585223013,\n",
       " 0.01222011329114846,\n",
       " 0.050407967325987395,\n",
       " 0.02444022658229692,\n",
       " 0.02601701539405801,\n",
       " 0.01222011329114846,\n",
       " 0.02444022658229692,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.02987138804502957,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.050407967325987395,\n",
       " 0.012408115034089204,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.047442792777399906,\n",
       " 0.017160159089697837,\n",
       " 0.020680191723482007,\n",
       " 0.042448814590305174,\n",
       " 0.01222011329114846,\n",
       " 0.02444022658229692,\n",
       " 0.031020287585223013,\n",
       " 0.018756452958506937,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.031020287585223013,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.04480708206754436,\n",
       " 0.019203035171804723,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.019203035171804723,\n",
       " 0.018756452958506937,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.023721396388699953,\n",
       " 0.05760910551541417,\n",
       " 0.04480708206754436,\n",
       " 0.023721396388699953,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.019203035171804723,\n",
       " 0.08961416413508871,\n",
       " 0.10081593465197479,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.04480708206754436,\n",
       " 0.018756452958506937,\n",
       " 0.028804552757707085,\n",
       " 0.047442792777399906,\n",
       " 0.028804552757707085,\n",
       " 0.02601701539405801,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.028804552757707085,\n",
       " 0.010340095861741004,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.019203035171804723,\n",
       " 0.02987138804502957,\n",
       " 0.012408115034089204,\n",
       " 0.02601701539405801,\n",
       " 0.042448814590305174,\n",
       " 0.02987138804502957,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.04480708206754436,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.042448814590305174,\n",
       " 0.012408115034089204,\n",
       " 0.031020287585223013,\n",
       " 0.028804552757707085,\n",
       " 0.017160159089697837,\n",
       " 0.02444022658229692,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.01222011329114846,\n",
       " 0.02987138804502957,\n",
       " 0.010340095861741004,\n",
       " 0.016130549544315965,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.04480708206754436,\n",
       " 0.05376849848105322,\n",
       " 0.04480708206754436,\n",
       " 0.023721396388699953,\n",
       " 0.018756452958506937,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.02987138804502957,\n",
       " 0.02444022658229692,\n",
       " 0.017160159089697837,\n",
       " 0.05376849848105322,\n",
       " 0.05376849848105322,\n",
       " 0.016130549544315965,\n",
       " 0.031020287585223013,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.028804552757707085,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.010340095861741004,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.050407967325987395,\n",
       " 0.016130549544315965,\n",
       " 0.031020287585223013,\n",
       " 0.05376849848105322,\n",
       " 0.012408115034089204,\n",
       " 0.10081593465197479,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.047442792777399906,\n",
       " 0.042448814590305174,\n",
       " 0.10081593465197479,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.02601701539405801,\n",
       " 0.050407967325987395,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.010340095861741004,\n",
       " 0.04480708206754436,\n",
       " 0.02444022658229692,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.02444022658229692,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.042448814590305174,\n",
       " 0.01222011329114846,\n",
       " 0.023721396388699953,\n",
       " 0.031020287585223013,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.023721396388699953,\n",
       " 0.04480708206754436,\n",
       " 0.012408115034089204,\n",
       " 0.05376849848105322,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.04480708206754436,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.050407967325987395,\n",
       " 0.10081593465197479,\n",
       " 0.019203035171804723,\n",
       " 0.050407967325987395,\n",
       " 0.018756452958506937,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.05760910551541417,\n",
       " 0.028804552757707085,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.023721396388699953,\n",
       " 0.010340095861741004,\n",
       " 0.02601701539405801,\n",
       " 0.10081593465197479,\n",
       " 0.02444022658229692,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.031020287585223013,\n",
       " 0.020680191723482007,\n",
       " 0.050407967325987395,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.018756452958506937,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.08961416413508871,\n",
       " 0.02987138804502957,\n",
       " 0.02987138804502957,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.02601701539405801,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.042448814590305174,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.012408115034089204,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.02444022658229692,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.02987138804502957,\n",
       " 0.023721396388699953,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.042448814590305174,\n",
       " 0.042448814590305174,\n",
       " 0.04480708206754436,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.019203035171804723,\n",
       " 0.019203035171804723,\n",
       " 0.016130549544315965,\n",
       " 0.02601701539405801,\n",
       " 0.028804552757707085,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.05376849848105322,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.04480708206754436,\n",
       " 0.010340095861741004,\n",
       " 0.042448814590305174,\n",
       " 0.010340095861741004,\n",
       " 0.02444022658229692,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.019203035171804723,\n",
       " 0.010340095861741004,\n",
       " 0.031020287585223013,\n",
       " 0.050407967325987395,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.02601701539405801,\n",
       " 0.018756452958506937,\n",
       " 0.08961416413508871,\n",
       " 0.017160159089697837,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.04480708206754436,\n",
       " 0.01222011329114846,\n",
       " 0.04480708206754436,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.019203035171804723,\n",
       " 0.016130549544315965,\n",
       " 0.02444022658229692,\n",
       " 0.10081593465197479,\n",
       " 0.012408115034089204,\n",
       " 0.05376849848105322,\n",
       " 0.018756452958506937,\n",
       " 0.016130549544315965,\n",
       " 0.02987138804502957,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.018756452958506937,\n",
       " 0.10081593465197479,\n",
       " 0.017160159089697837,\n",
       " 0.02444022658229692,\n",
       " 0.047442792777399906,\n",
       " 0.042448814590305174,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.019203035171804723,\n",
       " 0.031020287585223013,\n",
       " 0.016130549544315965,\n",
       " 0.02987138804502957,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.023721396388699953,\n",
       " 0.028804552757707085,\n",
       " 0.023721396388699953,\n",
       " 0.016130549544315965,\n",
       " 0.05376849848105322,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.016130549544315965,\n",
       " 0.023721396388699953,\n",
       " 0.023721396388699953,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.050407967325987395,\n",
       " 0.018756452958506937,\n",
       " 0.050407967325987395,\n",
       " 0.01222011329114846,\n",
       " 0.028804552757707085,\n",
       " 0.018756452958506937,\n",
       " 0.017160159089697837,\n",
       " 0.01222011329114846,\n",
       " 0.028804552757707085,\n",
       " 0.019203035171804723,\n",
       " 0.02987138804502957,\n",
       " 0.031020287585223013,\n",
       " 0.023721396388699953,\n",
       " 0.01222011329114846,\n",
       " 0.05376849848105322,\n",
       " 0.018756452958506937,\n",
       " 0.031020287585223013,\n",
       " 0.02987138804502957,\n",
       " 0.10081593465197479,\n",
       " 0.05760910551541417,\n",
       " 0.042448814590305174,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.012408115034089204]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = handler.calculate_class_weights(data_imbal[\"y_train\"])\n",
    "\n",
    "weights = [class_weights[label] for label in data_imbal['y_train']]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32429"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "\n",
    "class TextClassifier(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, embedding_matrix=None):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = Embedding(\n",
    "            vocab_size, \n",
    "            embed_dim, \n",
    "\n",
    "            weights=[embedding_matrix] if embedding_matrix is not None else None,\n",
    "            trainable=embedding_matrix is None\n",
    "        )\n",
    "        \n",
    "        # Multiple parallel convolution layers\n",
    "        self.conv1 = Conv1D(64, 3, activation='relu', padding='same')\n",
    "        self.conv2 = Conv1D(32, 4, activation='relu', padding='same')\n",
    "        self.conv3 = Conv1D(32, 5, activation='relu', padding='same')\n",
    "        \n",
    "        # Pooling layers\n",
    "        self.pool1 = GlobalMaxPooling1D()\n",
    "        self.pool2 = GlobalMaxPooling1D()\n",
    "        self.pool3 = GlobalMaxPooling1D()\n",
    "        \n",
    "        # Batch normalization and dropout\n",
    "        self.batch_norm1 = BatchNormalization()\n",
    "        self.dropout1 = Dropout(0.4)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.batch_norm2 = BatchNormalization()\n",
    "        self.dropout2 = Dropout(0.4)\n",
    "        \n",
    "        self.dense2 = Dense(64, activation='relu')\n",
    "        self.batch_norm3 = BatchNormalization()\n",
    "        self.dropout3 = Dropout(0.3)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        # Embedding\n",
    "        x = self.embedding(inputs)\n",
    "        \n",
    "        # Parallel convolutions\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(x)\n",
    "        conv3 = self.conv3(x)\n",
    "        \n",
    "        # Pooling\n",
    "        pool1 = self.pool1(conv1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "        pool3 = self.pool3(conv3)\n",
    "        \n",
    "        # Concatenate\n",
    "        concat = tf.keras.layers.concatenate([pool1, pool2, pool3])\n",
    "        \n",
    "        # First dense block\n",
    "        x = self.batch_norm1(concat, training=training)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        # Second dense block\n",
    "        x = self.batch_norm2(x, training=training)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        # Third dense block\n",
    "        x = self.batch_norm3(x, training=training)\n",
    "        x = self.dropout3(x, training=training)\n",
    "        \n",
    "        # Output\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL TRAINING [WITHOUT CLASS BALANCING]\n",
    "\n",
    "if data['embedding_matrix'] is not None:\n",
    "    vocab_size = data['embedding_matrix'].shape[0] \n",
    "\n",
    "# vocab_size\n",
    "# # Create and train model\n",
    "# model_basic = CustomTextClassifier(\n",
    "#     vocab_size=vocab_size,\n",
    "#     embedding_dim=preprocessor.embedding_dim,\n",
    "#     num_classes=data['num_classes'],\n",
    "#     embedding_matrix=data['embedding_matrix']\n",
    "# )\n",
    "\n",
    "model_2 = TextClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=preprocessor.embedding_dim,\n",
    "    num_classes=data['num_classes'],\n",
    "    embedding_matrix=data['embedding_matrix']\n",
    ")\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule)\n",
    "\n",
    "# Compile model\n",
    "model_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Weighted Class Balancing!\n",
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.0265 - loss: 0.1060 - val_accuracy: 0.0103 - val_loss: 4.4821\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0862 - loss: 0.0899 - val_accuracy: 0.0154 - val_loss: 4.2506\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1184 - loss: 0.0826 - val_accuracy: 0.1077 - val_loss: 3.2774\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1739 - loss: 0.0735 - val_accuracy: 0.1231 - val_loss: 2.9950\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.2052 - loss: 0.0674 - val_accuracy: 0.1641 - val_loss: 2.8688\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2466 - loss: 0.0645 - val_accuracy: 0.2051 - val_loss: 2.7458\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1974 - loss: 0.0626 - val_accuracy: 0.2821 - val_loss: 2.5620\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3083 - loss: 0.0565 - val_accuracy: 0.2974 - val_loss: 2.4145\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3421 - loss: 0.0534 - val_accuracy: 0.3282 - val_loss: 2.3340\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3667 - loss: 0.0520 - val_accuracy: 0.4051 - val_loss: 2.2471\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.3771 - loss: 0.0465 - val_accuracy: 0.4103 - val_loss: 2.1829\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4155 - loss: 0.0471 - val_accuracy: 0.4103 - val_loss: 2.1090\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4203 - loss: 0.0429 - val_accuracy: 0.4462 - val_loss: 2.0146\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.4701 - loss: 0.0418 - val_accuracy: 0.4513 - val_loss: 1.9872\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4716 - loss: 0.0391 - val_accuracy: 0.4615 - val_loss: 1.9239\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4697 - loss: 0.0408 - val_accuracy: 0.4667 - val_loss: 1.8648\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5293 - loss: 0.0372 - val_accuracy: 0.4615 - val_loss: 1.8633\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5295 - loss: 0.0341 - val_accuracy: 0.4564 - val_loss: 1.8696\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5196 - loss: 0.0344 - val_accuracy: 0.4769 - val_loss: 1.8261\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5282 - loss: 0.0347 - val_accuracy: 0.4923 - val_loss: 1.8048\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5621 - loss: 0.0325 - val_accuracy: 0.4667 - val_loss: 1.7749\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5779 - loss: 0.0299 - val_accuracy: 0.4718 - val_loss: 1.7321\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6200 - loss: 0.0277 - val_accuracy: 0.5128 - val_loss: 1.7139\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6091 - loss: 0.0296 - val_accuracy: 0.5179 - val_loss: 1.6992\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6131 - loss: 0.0287 - val_accuracy: 0.5077 - val_loss: 1.6634\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6227 - loss: 0.0264 - val_accuracy: 0.5077 - val_loss: 1.6812\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6062 - loss: 0.0281 - val_accuracy: 0.4821 - val_loss: 1.6692\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6554 - loss: 0.0239 - val_accuracy: 0.4974 - val_loss: 1.6557\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6676 - loss: 0.0245 - val_accuracy: 0.4872 - val_loss: 1.6404\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6464 - loss: 0.0252 - val_accuracy: 0.5026 - val_loss: 1.6751\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6685 - loss: 0.0219 - val_accuracy: 0.5179 - val_loss: 1.6971\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7246 - loss: 0.0207 - val_accuracy: 0.5026 - val_loss: 1.7085\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7413 - loss: 0.0190 - val_accuracy: 0.5179 - val_loss: 1.6699\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6726 - loss: 0.0203 - val_accuracy: 0.5128 - val_loss: 1.7105\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7177 - loss: 0.0184 - val_accuracy: 0.5179 - val_loss: 1.6879\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6975 - loss: 0.0203 - val_accuracy: 0.5333 - val_loss: 1.6824\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7242 - loss: 0.0190 - val_accuracy: 0.5538 - val_loss: 1.6685\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7519 - loss: 0.0183 - val_accuracy: 0.5436 - val_loss: 1.6902\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7275 - loss: 0.0171 - val_accuracy: 0.5231 - val_loss: 1.7083\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7157 - loss: 0.0190 - val_accuracy: 0.5026 - val_loss: 1.7564\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7263 - loss: 0.0193 - val_accuracy: 0.5026 - val_loss: 1.7714\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7462 - loss: 0.0177 - val_accuracy: 0.4974 - val_loss: 1.7722\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7919 - loss: 0.0156 - val_accuracy: 0.5282 - val_loss: 1.8157\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7760 - loss: 0.0173 - val_accuracy: 0.5128 - val_loss: 1.7622\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7515 - loss: 0.0164 - val_accuracy: 0.5128 - val_loss: 1.7788\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7816 - loss: 0.0159 - val_accuracy: 0.4974 - val_loss: 1.8426\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7754 - loss: 0.0156 - val_accuracy: 0.5026 - val_loss: 1.7585\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7691 - loss: 0.0162 - val_accuracy: 0.5333 - val_loss: 1.7208\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8211 - loss: 0.0132 - val_accuracy: 0.5128 - val_loss: 1.8376\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8109 - loss: 0.0134 - val_accuracy: 0.5026 - val_loss: 1.8525\n"
     ]
    }
   ],
   "source": [
    "# Train model with class weights if using weighted strategy\n",
    "if handler.strategy == \"weighted\":\n",
    "    print(\"Using Weighted Class Balancing!\")\n",
    "    history = model_2.fit(\n",
    "        data['train_dataset'],\n",
    "        validation_data=data['val_dataset'],\n",
    "        epochs=50,\n",
    "        # class_weight=data['class_weights']\n",
    "    )\n",
    "else:\n",
    "    print(\"Using NO Weighted Class Balancing!\")\n",
    "    history = model_2.fit(\n",
    "        data['train_dataset'],\n",
    "        validation_data=data['val_dataset'],\n",
    "        epochs=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(hitory, 'accuracy', 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.1240 - loss: 0.0777 - val_accuracy: 0.0923 - val_loss: 3.0537\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.1028 - loss: 0.0773 - val_accuracy: 0.0718 - val_loss: 3.0991\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.1153 - loss: 0.0764 - val_accuracy: 0.1026 - val_loss: 3.0550\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.1252 - loss: 0.0783 - val_accuracy: 0.0769 - val_loss: 3.0642\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.1073 - loss: 0.0702 - val_accuracy: 0.0769 - val_loss: 3.0796\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.1576 - loss: 0.0727 - val_accuracy: 0.1026 - val_loss: 3.0664\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.1148 - loss: 0.0740 - val_accuracy: 0.0769 - val_loss: 3.0594\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.1452 - loss: 0.0729 - val_accuracy: 0.0974 - val_loss: 3.0508\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.1107 - loss: 0.0767 - val_accuracy: 0.0974 - val_loss: 3.0539\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.1433 - loss: 0.0698 - val_accuracy: 0.0974 - val_loss: 3.0757\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    data['train_dataset'],\n",
    "    validation_data=data['val_dataset'],\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Randoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.matrix([[1, 0, 1], [0, 1, 1], [0, 0, 1]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B - (1 * I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 0],\n",
       "       [6, 6, 8],\n",
       "       [2, 2, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 9, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 0],\n",
       "       [0, 6, 0],\n",
       "       [1, 2, 8]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[2, 5, 0], [0, 6, 0], [1, 2, 8]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8., 2., 6.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 1, 0], [0, 1, 2], [0, 0, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0],\n",
       "       [0, 1, 2],\n",
       "       [0, 0, 3]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EigResult(eigenvalues=array([1., 1., 3.]), eigenvectors=array([[ 1.00000000e+00, -1.00000000e+00,  3.33333333e-01],\n",
       "       [ 0.00000000e+00,  2.22044605e-16,  6.66666667e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  6.66666667e-01]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_stock_data(tickers, days_back=30):\n",
    "    \"\"\"\n",
    "    Fetch stock data for given tickers for a specified number of days.\n",
    "    \n",
    "    Parameters:\n",
    "    tickers (list): List of stock ticker symbols (e.g., ['AAPL', 'GOOGL'])\n",
    "    days_back (int): Number of days of historical data to fetch\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing DataFrames with stock data for each ticker\n",
    "    \"\"\"\n",
    "    # Calculate date range\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days_back)\n",
    "    \n",
    "    stock_data = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Create ticker object\n",
    "            stock = yf.Ticker(ticker)\n",
    "            \n",
    "            # Fetch historical data\n",
    "            hist_data = stock.history(start=start_date, end=end_date)\n",
    "            \n",
    "            # Get additional stock info\n",
    "            info = stock.info\n",
    "            \n",
    "            # Add important info to the DataFrame\n",
    "            hist_data['Symbol'] = ticker\n",
    "            hist_data['Company_Name'] = info.get('longName', '')\n",
    "            hist_data['Industry'] = info.get('industry', '')\n",
    "            hist_data['Sector'] = info.get('sector', '')\n",
    "            hist_data['Market_Cap'] = info.get('marketCap', '')\n",
    "            \n",
    "            # Calculate daily returns\n",
    "            hist_data['Daily_Return'] = hist_data['Close'].pct_change()\n",
    "            \n",
    "            # Format the data\n",
    "            hist_data = hist_data.round(2)\n",
    "            \n",
    "            stock_data[ticker] = hist_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {str(e)}\")\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "def get_latest_prices(stock_data):\n",
    "    \"\"\"\n",
    "    Extract the most recent closing prices and details for each stock.\n",
    "    \n",
    "    Parameters:\n",
    "    stock_data (dict): Dictionary of stock DataFrames from fetch_stock_data\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Latest closing prices and details for each stock\n",
    "    \"\"\"\n",
    "    latest_data = []\n",
    "    \n",
    "    for ticker, data in stock_data.items():\n",
    "        if not data.empty:\n",
    "            latest = data.iloc[-1]\n",
    "            latest_data.append({\n",
    "                'Symbol': ticker,\n",
    "                'Company_Name': latest['Company_Name'],\n",
    "                'Close': latest['Close'],\n",
    "                'Volume': latest['Volume'],\n",
    "                'Daily_Return': latest['Daily_Return'],\n",
    "                'Industry': latest['Industry'],\n",
    "                'Sector': latest['Sector'],\n",
    "                'Market_Cap': latest['Market_Cap']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(latest_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
