{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text data...\n",
      "Found potentially problematic words:\n",
      "Problem word: ntp\n",
      "Problem word: ntp\n",
      "Found potentially problematic words:\n",
      "Problem word: npc\n",
      "Found potentially problematic words:\n",
      "Problem word: nac\n",
      "Problem word: nac\n",
      "Tokenizing text...\n",
      "Splitting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projs\\COde\\ResAnalysis\\resanalysis\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# Append the parent directory to the system path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from src.preprocessing.data_preprocessing import ResumeTextPreprocessor, NLPPreprocessor, ImbalancedNLPHandler\n",
    "from src.training.training import call_data, create_and_compile_model\n",
    "from src.model.model import TextAnalysisModel2, TextClassifier\n",
    "\n",
    "from src.utils.helpers import plot_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b\"Free Flight Attendant Resume\\nDarlene Flint\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Corporate Flight Attendant Resume\\nCAITLIN F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Entry Level Resume Guide\\n\\nThis packet is i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Category                                             Resume\n",
       "0        1        HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...\n",
       "1        2        HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...\n",
       "2        3        HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...\n",
       "3        4        HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...\n",
       "4        5        HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...\n",
       "...    ...       ...                                                ...\n",
       "1214  1215  Aviation  b\"Free Flight Attendant Resume\\nDarlene Flint\\...\n",
       "1215  1216  Aviation  b'Corporate Flight Attendant Resume\\nCAITLIN F...\n",
       "1216  1217  Aviation  b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...\n",
       "1217  1218  Aviation  b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...\n",
       "1218  1219  Aviation  b'Entry Level Resume Guide\\n\\nThis packet is i...\n",
       "\n",
       "[1219 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = call_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILIZING EXISITING PREPROCESSOR\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "\n",
    "class ImbalancedNLPHandler:\n",
    "    def __init__(self,\n",
    "                 preprocessor: NLPPreprocessor,\n",
    "                 strategy: str = \"weighted\"):\n",
    "        \"\"\"\n",
    "        Combines NLPPreprocessor with imbalanced data handling.\n",
    "        \n",
    "        Args:\n",
    "            preprocessor: Existing NLPPreprocessor instance\n",
    "            strategy: \"weighted\", \"oversample\", or \"undersample\"\n",
    "        \"\"\"\n",
    "        self.preprocessor = preprocessor\n",
    "        self.strategy = strategy\n",
    "    \n",
    "    def calculate_class_weights(self, labels: List) -> Dict:\n",
    "        \"\"\"Calculate class weights for imbalanced data.\"\"\"\n",
    "        class_counts = Counter(labels)\n",
    "        total = len(labels)\n",
    "        weights = {cls: total / count for cls, count in class_counts.items()}\n",
    "        \n",
    "        # Normalize weights\n",
    "        weight_sum = sum(weights.values())\n",
    "        weights = {cls: weight / weight_sum for cls, weight in weights.items()}\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def oversample(self, texts: List[str], labels: List) -> Tuple[List[str], List]:\n",
    "        \"\"\"Oversample minority classes.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        majority_size = max(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) < majority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=True,\n",
    "                                   n_samples=majority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "    \n",
    "    def undersample(self, texts: List[str], labels: List) -> Tuple[List[str], List]:\n",
    "        \"\"\"Undersample majority classes.\"\"\"\n",
    "        df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "        class_counts = Counter(labels)\n",
    "        minority_size = min(class_counts.values())\n",
    "        \n",
    "        balanced_dfs = []\n",
    "        for label in class_counts.keys():\n",
    "            class_df = df[df['label'] == label]\n",
    "            if len(class_df) > minority_size:\n",
    "                resampled = resample(class_df,\n",
    "                                   replace=False,\n",
    "                                   n_samples=minority_size,\n",
    "                                   random_state=42)\n",
    "                balanced_dfs.append(resampled)\n",
    "            else:\n",
    "                balanced_dfs.append(class_df)\n",
    "        \n",
    "        balanced_df = pd.concat(balanced_dfs)\n",
    "        return balanced_df['text'].tolist(), balanced_df['label'].tolist()\n",
    "\n",
    "    def prepare_balanced_data(self, texts: List[str], labels: List, use_word2vec: bool = False):\n",
    "        \"\"\"Prepare data with imbalance handling.\"\"\"\n",
    "        # Apply balancing strategy if needed\n",
    "        if self.strategy == \"oversample\":\n",
    "            texts, labels = self.oversample(texts, labels)\n",
    "        elif self.strategy == \"undersample\":\n",
    "            texts, labels = self.undersample(texts, labels)\n",
    "        \n",
    "        # Use existing preprocessor to prepare data\n",
    "        data = self.preprocessor.prepare_data(texts, labels, use_word2vec)\n",
    "        \n",
    "        # Add class weights if using weighted strategy\n",
    "        if self.strategy == \"weighted\":\n",
    "            class_weights = self.calculate_class_weights(data['y_train'])\n",
    "            data['class_weights'] = class_weights\n",
    "            \n",
    "            # Update datasets to use sample weights\n",
    "            weights = [class_weights[label] for label in data['y_train']]\n",
    "            data['train_dataset'] = tf.data.Dataset.from_tensor_slices(\n",
    "                (data['X_train'], data['y_train'], weights)\n",
    "            ).shuffle(10000).batch(32)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def get_class_distribution(self, labels: List) -> Dict:\n",
    "        \"\"\"Calculate class distribution percentages.\"\"\"\n",
    "        total = len(labels)\n",
    "        class_counts = Counter(labels)\n",
    "        return {label: count/total * 100 for label, count in class_counts.items()}\n",
    "\n",
    "# Example custom model that can use the preprocessor's word2vec embeddings\n",
    "class CustomTextClassifier(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = tf.keras.layers.Embedding(\n",
    "                vocab_size, embedding_dim,\n",
    "                weights=[embedding_matrix],\n",
    "                trainable=False\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "            \n",
    "        self.lstm = tf.keras.layers.LSTM(64)\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.lstm(x)\n",
    "        x = self.dense1(x)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1215</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b\"Free Flight Attendant Resume\\nDarlene Flint\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1216</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Corporate Flight Attendant Resume\\nCAITLIN F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1217</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1218</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>1219</td>\n",
       "      <td>Aviation</td>\n",
       "      <td>b'Entry Level Resume Guide\\n\\nThis packet is i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Category                                             Resume\n",
       "0        1        HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...\n",
       "1        2        HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...\n",
       "2        3        HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...\n",
       "3        4        HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...\n",
       "4        5        HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...\n",
       "...    ...       ...                                                ...\n",
       "1214  1215  Aviation  b\"Free Flight Attendant Resume\\nDarlene Flint\\...\n",
       "1215  1216  Aviation  b'Corporate Flight Attendant Resume\\nCAITLIN F...\n",
       "1216  1217  Aviation  b'MAJOR CONRAD A. PREEDOM\\n2354 Fairchild Dr.,...\n",
       "1217  1218  Aviation  b'STACY SAMPLE\\n\\n702 800-0000 cell\\n\\n0000@em...\n",
       "1218  1219  Aviation  b'Entry Level Resume Guide\\n\\nThis packet is i...\n",
       "\n",
       "[1219 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found potentially problematic words:\n",
      "Problem word: ntp\n",
      "Problem word: ntp\n",
      "Found potentially problematic words:\n",
      "Problem word: npc\n",
      "Found potentially problematic words:\n",
      "Problem word: nac\n",
      "Problem word: nac\n",
      "Analyzing text characteristics...\n",
      "Average length: 607.49\n",
      "Median length: 317.00\n",
      "95th percentile length: 2605.00\n",
      "Max length: 6149\n",
      "Total unique words: 32427\n",
      "Words appearing only once: 12713\n",
      "Tokenizing texts...\n",
      "Creating Word2Vec embeddings...\n",
      "Splitting data...\n",
      "Creating TF datasets...\n"
     ]
    }
   ],
   "source": [
    "data['cleaned_text'] = data['Resume'].apply(ResumeTextPreprocessor().process_and_check)\n",
    "\n",
    "# # Initialize your existing preprocessor\n",
    "# preprocessor = NLPPreprocessor(\n",
    "#     max_words=10000,\n",
    "#     max_length=500,\n",
    "#     embedding_dim=100\n",
    "# )\n",
    "\n",
    "# Using your preprocessor\n",
    "preprocessor = NLPPreprocessor(\n",
    "    max_words=10000,\n",
    "    max_length=500,\n",
    "    embedding_dim=100,\n",
    "    TFDataset=True\n",
    ")\n",
    "data_imbal = preprocessor.prepare_data(\n",
    "    texts=data['cleaned_text'],\n",
    "    labels=data['Category'],\n",
    "    use_word2vec=True  # Use Word2Vec embeddings\n",
    ")\n",
    "# data2\n",
    "\n",
    "if data_imbal['embedding_matrix'] is not None:\n",
    "        vocab_size = data_imbal['embedding_matrix'].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class distribution: {'HR': 3.3634126333059884, 'Designing': 4.1837571780147655, 'Managment': 6.070549630844955, 'Information Technology': 8.531583264971287, 'Education': 8.367514356029531, 'Advocate': 5.004101722723544, 'Business Development': 3.6095159967186223, 'Health & Fitness': 6.316652994257588, 'Agricultural': 1.9688269073010665, 'BPO': 2.0508613617719442, 'Sales': 5.004101722723544, 'Consultant': 2.1328958162428218, 'Digital Media': 4.4298605414273995, 'Automobile': 2.2149302707136997, 'Food & Beverages': 1.8047579983593112, 'Finance': 5.414273995077933, 'Apparel': 1.1484823625922889, 'Engineering': 9.92616899097621, 'Accountant': 5.496308449548811, 'Building & Construction': 2.3789991796554553, 'Architects': 0.9844134536505332, 'Public Relations': 1.0664479081214109, 'Banking': 3.937653814602133, 'Arts': 3.5274815422477444, 'Aviation': 1.0664479081214109}\n"
     ]
    }
   ],
   "source": [
    "# Create the imbalanced handler with your preprocessor\n",
    "handler = ImbalancedNLPHandler(\n",
    "    preprocessor=preprocessor,\n",
    "    # strategy=\"weighted\"\n",
    "    strategy=\"oversample\"  # \"weighted\" or \"oversample\" or \"undersample\"\n",
    "    # strategy=\"undersample\"\n",
    ")\n",
    "\n",
    "# Check initial class distribution\n",
    "initial_dist = handler.get_class_distribution(data[\"Category\"])\n",
    "print(\"Initial class distribution:\", initial_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing text characteristics...\n",
      "Average length: 562.50\n",
      "Median length: 308.00\n",
      "95th percentile length: 1953.80\n",
      "Max length: 5747\n",
      "Total unique words: 30307\n",
      "Words appearing only once: 4695\n",
      "Tokenizing texts...\n",
      "Creating Word2Vec embeddings...\n",
      "Splitting data...\n",
      "Creating TF datasets...\n"
     ]
    }
   ],
   "source": [
    "# Prepare data with imbalance handling\n",
    "data = handler.prepare_balanced_data(data[\"cleaned_text\"], data[\"Category\"], use_word2vec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.023721396388699953,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.10081593465197479,\n",
       " 0.023721396388699953,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.028804552757707085,\n",
       " 0.012408115034089204,\n",
       " 0.02987138804502957,\n",
       " 0.018756452958506937,\n",
       " 0.01222011329114846,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.042448814590305174,\n",
       " 0.010340095861741004,\n",
       " 0.10081593465197479,\n",
       " 0.010340095861741004,\n",
       " 0.10081593465197479,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.028804552757707085,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.012408115034089204,\n",
       " 0.02601701539405801,\n",
       " 0.02601701539405801,\n",
       " 0.031020287585223013,\n",
       " 0.023721396388699953,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.018756452958506937,\n",
       " 0.02987138804502957,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.02601701539405801,\n",
       " 0.02601701539405801,\n",
       " 0.031020287585223013,\n",
       " 0.019203035171804723,\n",
       " 0.01222011329114846,\n",
       " 0.02444022658229692,\n",
       " 0.028804552757707085,\n",
       " 0.02601701539405801,\n",
       " 0.017160159089697837,\n",
       " 0.02601701539405801,\n",
       " 0.01222011329114846,\n",
       " 0.031020287585223013,\n",
       " 0.05376849848105322,\n",
       " 0.02444022658229692,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.031020287585223013,\n",
       " 0.023721396388699953,\n",
       " 0.018756452958506937,\n",
       " 0.02601701539405801,\n",
       " 0.10081593465197479,\n",
       " 0.023721396388699953,\n",
       " 0.018756452958506937,\n",
       " 0.028804552757707085,\n",
       " 0.02444022658229692,\n",
       " 0.05376849848105322,\n",
       " 0.02601701539405801,\n",
       " 0.017160159089697837,\n",
       " 0.016130549544315965,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.019203035171804723,\n",
       " 0.031020287585223013,\n",
       " 0.10081593465197479,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.018756452958506937,\n",
       " 0.10081593465197479,\n",
       " 0.031020287585223013,\n",
       " 0.02601701539405801,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.019203035171804723,\n",
       " 0.016130549544315965,\n",
       " 0.05760910551541417,\n",
       " 0.02987138804502957,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.023721396388699953,\n",
       " 0.017160159089697837,\n",
       " 0.04480708206754436,\n",
       " 0.01222011329114846,\n",
       " 0.10081593465197479,\n",
       " 0.019203035171804723,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.047442792777399906,\n",
       " 0.031020287585223013,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.05760910551541417,\n",
       " 0.017160159089697837,\n",
       " 0.05760910551541417,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.028804552757707085,\n",
       " 0.012408115034089204,\n",
       " 0.028804552757707085,\n",
       " 0.042448814590305174,\n",
       " 0.019203035171804723,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.019203035171804723,\n",
       " 0.02987138804502957,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.02444022658229692,\n",
       " 0.018756452958506937,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.05760910551541417,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.016130549544315965,\n",
       " 0.028804552757707085,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.018756452958506937,\n",
       " 0.10081593465197479,\n",
       " 0.047442792777399906,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.02987138804502957,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.04480708206754436,\n",
       " 0.08961416413508871,\n",
       " 0.01222011329114846,\n",
       " 0.02601701539405801,\n",
       " 0.047442792777399906,\n",
       " 0.016130549544315965,\n",
       " 0.050407967325987395,\n",
       " 0.020680191723482007,\n",
       " 0.050407967325987395,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.05376849848105322,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.05376849848105322,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.017160159089697837,\n",
       " 0.02601701539405801,\n",
       " 0.010340095861741004,\n",
       " 0.05376849848105322,\n",
       " 0.028804552757707085,\n",
       " 0.020680191723482007,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.018756452958506937,\n",
       " 0.031020287585223013,\n",
       " 0.023721396388699953,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.017160159089697837,\n",
       " 0.023721396388699953,\n",
       " 0.018756452958506937,\n",
       " 0.02987138804502957,\n",
       " 0.047442792777399906,\n",
       " 0.020680191723482007,\n",
       " 0.028804552757707085,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.02601701539405801,\n",
       " 0.028804552757707085,\n",
       " 0.012408115034089204,\n",
       " 0.019203035171804723,\n",
       " 0.047442792777399906,\n",
       " 0.02601701539405801,\n",
       " 0.023721396388699953,\n",
       " 0.010340095861741004,\n",
       " 0.042448814590305174,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.02601701539405801,\n",
       " 0.08961416413508871,\n",
       " 0.02444022658229692,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.02444022658229692,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.012408115034089204,\n",
       " 0.02987138804502957,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.042448814590305174,\n",
       " 0.01222011329114846,\n",
       " 0.10081593465197479,\n",
       " 0.019203035171804723,\n",
       " 0.010340095861741004,\n",
       " 0.017160159089697837,\n",
       " 0.023721396388699953,\n",
       " 0.023721396388699953,\n",
       " 0.031020287585223013,\n",
       " 0.10081593465197479,\n",
       " 0.028804552757707085,\n",
       " 0.02987138804502957,\n",
       " 0.047442792777399906,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.08961416413508871,\n",
       " 0.010340095861741004,\n",
       " 0.031020287585223013,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.05760910551541417,\n",
       " 0.017160159089697837,\n",
       " 0.028804552757707085,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.10081593465197479,\n",
       " 0.028804552757707085,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.017160159089697837,\n",
       " 0.028804552757707085,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.04480708206754436,\n",
       " 0.018756452958506937,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.012408115034089204,\n",
       " 0.023721396388699953,\n",
       " 0.047442792777399906,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.028804552757707085,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.02444022658229692,\n",
       " 0.05760910551541417,\n",
       " 0.047442792777399906,\n",
       " 0.016130549544315965,\n",
       " 0.047442792777399906,\n",
       " 0.028804552757707085,\n",
       " 0.028804552757707085,\n",
       " 0.010340095861741004,\n",
       " 0.050407967325987395,\n",
       " 0.10081593465197479,\n",
       " 0.020680191723482007,\n",
       " 0.017160159089697837,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.031020287585223013,\n",
       " 0.050407967325987395,\n",
       " 0.050407967325987395,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.047442792777399906,\n",
       " 0.08961416413508871,\n",
       " 0.042448814590305174,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.023721396388699953,\n",
       " 0.05760910551541417,\n",
       " 0.050407967325987395,\n",
       " 0.016130549544315965,\n",
       " 0.019203035171804723,\n",
       " 0.010340095861741004,\n",
       " 0.023721396388699953,\n",
       " 0.017160159089697837,\n",
       " 0.012408115034089204,\n",
       " 0.05376849848105322,\n",
       " 0.010340095861741004,\n",
       " 0.02601701539405801,\n",
       " 0.018756452958506937,\n",
       " 0.047442792777399906,\n",
       " 0.05760910551541417,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.019203035171804723,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.017160159089697837,\n",
       " 0.019203035171804723,\n",
       " 0.02601701539405801,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.05760910551541417,\n",
       " 0.023721396388699953,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.02444022658229692,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.10081593465197479,\n",
       " 0.020680191723482007,\n",
       " 0.08961416413508871,\n",
       " 0.047442792777399906,\n",
       " 0.018756452958506937,\n",
       " 0.012408115034089204,\n",
       " 0.08961416413508871,\n",
       " 0.020680191723482007,\n",
       " 0.10081593465197479,\n",
       " 0.05760910551541417,\n",
       " 0.02987138804502957,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.017160159089697837,\n",
       " 0.020680191723482007,\n",
       " 0.042448814590305174,\n",
       " 0.02987138804502957,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.017160159089697837,\n",
       " 0.012408115034089204,\n",
       " 0.023721396388699953,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.016130549544315965,\n",
       " 0.05760910551541417,\n",
       " 0.018756452958506937,\n",
       " 0.028804552757707085,\n",
       " 0.01222011329114846,\n",
       " 0.023721396388699953,\n",
       " 0.01222011329114846,\n",
       " 0.031020287585223013,\n",
       " 0.04480708206754436,\n",
       " 0.10081593465197479,\n",
       " 0.031020287585223013,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.042448814590305174,\n",
       " 0.042448814590305174,\n",
       " 0.017160159089697837,\n",
       " 0.02601701539405801,\n",
       " 0.031020287585223013,\n",
       " 0.10081593465197479,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.047442792777399906,\n",
       " 0.04480708206754436,\n",
       " 0.019203035171804723,\n",
       " 0.02444022658229692,\n",
       " 0.031020287585223013,\n",
       " 0.01222011329114846,\n",
       " 0.050407967325987395,\n",
       " 0.02444022658229692,\n",
       " 0.02601701539405801,\n",
       " 0.01222011329114846,\n",
       " 0.02444022658229692,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.02987138804502957,\n",
       " 0.02601701539405801,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.050407967325987395,\n",
       " 0.012408115034089204,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.047442792777399906,\n",
       " 0.017160159089697837,\n",
       " 0.020680191723482007,\n",
       " 0.042448814590305174,\n",
       " 0.01222011329114846,\n",
       " 0.02444022658229692,\n",
       " 0.031020287585223013,\n",
       " 0.018756452958506937,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.031020287585223013,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.04480708206754436,\n",
       " 0.019203035171804723,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.019203035171804723,\n",
       " 0.018756452958506937,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.023721396388699953,\n",
       " 0.05760910551541417,\n",
       " 0.04480708206754436,\n",
       " 0.023721396388699953,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.019203035171804723,\n",
       " 0.08961416413508871,\n",
       " 0.10081593465197479,\n",
       " 0.01222011329114846,\n",
       " 0.010340095861741004,\n",
       " 0.04480708206754436,\n",
       " 0.018756452958506937,\n",
       " 0.028804552757707085,\n",
       " 0.047442792777399906,\n",
       " 0.028804552757707085,\n",
       " 0.02601701539405801,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.028804552757707085,\n",
       " 0.010340095861741004,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.019203035171804723,\n",
       " 0.02987138804502957,\n",
       " 0.012408115034089204,\n",
       " 0.02601701539405801,\n",
       " 0.042448814590305174,\n",
       " 0.02987138804502957,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.04480708206754436,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.042448814590305174,\n",
       " 0.012408115034089204,\n",
       " 0.031020287585223013,\n",
       " 0.028804552757707085,\n",
       " 0.017160159089697837,\n",
       " 0.02444022658229692,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.01222011329114846,\n",
       " 0.02987138804502957,\n",
       " 0.010340095861741004,\n",
       " 0.016130549544315965,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.012408115034089204,\n",
       " 0.04480708206754436,\n",
       " 0.05376849848105322,\n",
       " 0.04480708206754436,\n",
       " 0.023721396388699953,\n",
       " 0.018756452958506937,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.019203035171804723,\n",
       " 0.02987138804502957,\n",
       " 0.02444022658229692,\n",
       " 0.017160159089697837,\n",
       " 0.05376849848105322,\n",
       " 0.05376849848105322,\n",
       " 0.016130549544315965,\n",
       " 0.031020287585223013,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.028804552757707085,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.010340095861741004,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.017160159089697837,\n",
       " 0.017160159089697837,\n",
       " 0.050407967325987395,\n",
       " 0.016130549544315965,\n",
       " 0.031020287585223013,\n",
       " 0.05376849848105322,\n",
       " 0.012408115034089204,\n",
       " 0.10081593465197479,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.047442792777399906,\n",
       " 0.042448814590305174,\n",
       " 0.10081593465197479,\n",
       " 0.020680191723482007,\n",
       " 0.019203035171804723,\n",
       " 0.02601701539405801,\n",
       " 0.050407967325987395,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.018756452958506937,\n",
       " 0.010340095861741004,\n",
       " 0.04480708206754436,\n",
       " 0.02444022658229692,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.02444022658229692,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.042448814590305174,\n",
       " 0.01222011329114846,\n",
       " 0.023721396388699953,\n",
       " 0.031020287585223013,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.023721396388699953,\n",
       " 0.04480708206754436,\n",
       " 0.012408115034089204,\n",
       " 0.05376849848105322,\n",
       " 0.020680191723482007,\n",
       " 0.010340095861741004,\n",
       " 0.04480708206754436,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.050407967325987395,\n",
       " 0.10081593465197479,\n",
       " 0.019203035171804723,\n",
       " 0.050407967325987395,\n",
       " 0.018756452958506937,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.019203035171804723,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.016130549544315965,\n",
       " 0.05760910551541417,\n",
       " 0.028804552757707085,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.023721396388699953,\n",
       " 0.010340095861741004,\n",
       " 0.02601701539405801,\n",
       " 0.10081593465197479,\n",
       " 0.02444022658229692,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.031020287585223013,\n",
       " 0.020680191723482007,\n",
       " 0.050407967325987395,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.018756452958506937,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.08961416413508871,\n",
       " 0.02987138804502957,\n",
       " 0.02987138804502957,\n",
       " 0.01222011329114846,\n",
       " 0.012408115034089204,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.02601701539405801,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.042448814590305174,\n",
       " 0.012408115034089204,\n",
       " 0.012408115034089204,\n",
       " 0.02444022658229692,\n",
       " 0.012408115034089204,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.02444022658229692,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.02987138804502957,\n",
       " 0.023721396388699953,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.042448814590305174,\n",
       " 0.042448814590305174,\n",
       " 0.04480708206754436,\n",
       " 0.020680191723482007,\n",
       " 0.01222011329114846,\n",
       " 0.019203035171804723,\n",
       " 0.019203035171804723,\n",
       " 0.016130549544315965,\n",
       " 0.02601701539405801,\n",
       " 0.028804552757707085,\n",
       " 0.017160159089697837,\n",
       " 0.010340095861741004,\n",
       " 0.05376849848105322,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.04480708206754436,\n",
       " 0.010340095861741004,\n",
       " 0.042448814590305174,\n",
       " 0.010340095861741004,\n",
       " 0.02444022658229692,\n",
       " 0.01222011329114846,\n",
       " 0.01222011329114846,\n",
       " 0.018756452958506937,\n",
       " 0.019203035171804723,\n",
       " 0.010340095861741004,\n",
       " 0.031020287585223013,\n",
       " 0.050407967325987395,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.02601701539405801,\n",
       " 0.018756452958506937,\n",
       " 0.08961416413508871,\n",
       " 0.017160159089697837,\n",
       " 0.019203035171804723,\n",
       " 0.020680191723482007,\n",
       " 0.04480708206754436,\n",
       " 0.01222011329114846,\n",
       " 0.04480708206754436,\n",
       " 0.016130549544315965,\n",
       " 0.018756452958506937,\n",
       " 0.010340095861741004,\n",
       " 0.01222011329114846,\n",
       " 0.017160159089697837,\n",
       " 0.019203035171804723,\n",
       " 0.016130549544315965,\n",
       " 0.02444022658229692,\n",
       " 0.10081593465197479,\n",
       " 0.012408115034089204,\n",
       " 0.05376849848105322,\n",
       " 0.018756452958506937,\n",
       " 0.016130549544315965,\n",
       " 0.02987138804502957,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.020680191723482007,\n",
       " 0.012408115034089204,\n",
       " 0.018756452958506937,\n",
       " 0.10081593465197479,\n",
       " 0.017160159089697837,\n",
       " 0.02444022658229692,\n",
       " 0.047442792777399906,\n",
       " 0.042448814590305174,\n",
       " 0.012408115034089204,\n",
       " 0.016130549544315965,\n",
       " 0.020680191723482007,\n",
       " 0.02444022658229692,\n",
       " 0.019203035171804723,\n",
       " 0.031020287585223013,\n",
       " 0.016130549544315965,\n",
       " 0.02987138804502957,\n",
       " 0.010340095861741004,\n",
       " 0.012408115034089204,\n",
       " 0.023721396388699953,\n",
       " 0.028804552757707085,\n",
       " 0.023721396388699953,\n",
       " 0.016130549544315965,\n",
       " 0.05376849848105322,\n",
       " 0.016130549544315965,\n",
       " 0.010340095861741004,\n",
       " 0.020680191723482007,\n",
       " 0.023721396388699953,\n",
       " 0.016130549544315965,\n",
       " 0.023721396388699953,\n",
       " 0.023721396388699953,\n",
       " 0.016130549544315965,\n",
       " 0.01222011329114846,\n",
       " 0.050407967325987395,\n",
       " 0.018756452958506937,\n",
       " 0.050407967325987395,\n",
       " 0.01222011329114846,\n",
       " 0.028804552757707085,\n",
       " 0.018756452958506937,\n",
       " 0.017160159089697837,\n",
       " 0.01222011329114846,\n",
       " 0.028804552757707085,\n",
       " 0.019203035171804723,\n",
       " 0.02987138804502957,\n",
       " 0.031020287585223013,\n",
       " 0.023721396388699953,\n",
       " 0.01222011329114846,\n",
       " 0.05376849848105322,\n",
       " 0.018756452958506937,\n",
       " 0.031020287585223013,\n",
       " 0.02987138804502957,\n",
       " 0.10081593465197479,\n",
       " 0.05760910551541417,\n",
       " 0.042448814590305174,\n",
       " 0.017160159089697837,\n",
       " 0.02987138804502957,\n",
       " 0.012408115034089204]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = handler.calculate_class_weights(data_imbal[\"y_train\"])\n",
    "\n",
    "weights = [class_weights[label] for label in data_imbal['y_train']]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32429"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "\n",
    "class TextClassifier(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, embedding_matrix=None):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = Embedding(\n",
    "            vocab_size, \n",
    "            embed_dim, \n",
    "\n",
    "            weights=[embedding_matrix] if embedding_matrix is not None else None,\n",
    "            trainable=embedding_matrix is None\n",
    "        )\n",
    "        \n",
    "        # Multiple parallel convolution layers\n",
    "        self.conv1 = Conv1D(64, 3, activation='relu', padding='same')\n",
    "        self.conv2 = Conv1D(32, 4, activation='relu', padding='same')\n",
    "        self.conv3 = Conv1D(32, 5, activation='relu', padding='same')\n",
    "        \n",
    "        # Pooling layers\n",
    "        self.pool1 = GlobalMaxPooling1D()\n",
    "        self.pool2 = GlobalMaxPooling1D()\n",
    "        self.pool3 = GlobalMaxPooling1D()\n",
    "        \n",
    "        # Batch normalization and dropout\n",
    "        self.batch_norm1 = BatchNormalization()\n",
    "        self.dropout1 = Dropout(0.4)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.batch_norm2 = BatchNormalization()\n",
    "        self.dropout2 = Dropout(0.4)\n",
    "        \n",
    "        self.dense2 = Dense(64, activation='relu')\n",
    "        self.batch_norm3 = BatchNormalization()\n",
    "        self.dropout3 = Dropout(0.3)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        # Embedding\n",
    "        x = self.embedding(inputs)\n",
    "        \n",
    "        # Parallel convolutions\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(x)\n",
    "        conv3 = self.conv3(x)\n",
    "        \n",
    "        # Pooling\n",
    "        pool1 = self.pool1(conv1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "        pool3 = self.pool3(conv3)\n",
    "        \n",
    "        # Concatenate\n",
    "        concat = tf.keras.layers.concatenate([pool1, pool2, pool3])\n",
    "        \n",
    "        # First dense block\n",
    "        x = self.batch_norm1(concat, training=training)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        # Second dense block\n",
    "        x = self.batch_norm2(x, training=training)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        # Third dense block\n",
    "        x = self.batch_norm3(x, training=training)\n",
    "        x = self.dropout3(x, training=training)\n",
    "        \n",
    "        # Output\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL TRAINING [WITHOUT CLASS BALANCING]\n",
    "\n",
    "if data['embedding_matrix'] is not None:\n",
    "    vocab_size = data['embedding_matrix'].shape[0] \n",
    "\n",
    "# vocab_size\n",
    "# # Create and train model\n",
    "# model_basic = CustomTextClassifier(\n",
    "#     vocab_size=vocab_size,\n",
    "#     embedding_dim=preprocessor.embedding_dim,\n",
    "#     num_classes=data['num_classes'],\n",
    "#     embedding_matrix=data['embedding_matrix']\n",
    "# )\n",
    "\n",
    "model_2 = TextClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=preprocessor.embedding_dim,\n",
    "    num_classes=data['num_classes'],\n",
    "    embedding_matrix=data['embedding_matrix']\n",
    ")\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule)\n",
    "\n",
    "# Compile model\n",
    "model_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NO Weighted Class Balancing!\n",
      "Epoch 1/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.0691 - loss: 3.7777 - val_accuracy: 0.0661 - val_loss: 3.8439\n",
      "Epoch 2/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.2163 - loss: 2.7638 - val_accuracy: 0.2562 - val_loss: 2.5922\n",
      "Epoch 3/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3447 - loss: 2.2777 - val_accuracy: 0.5165 - val_loss: 1.8473\n",
      "Epoch 4/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4235 - loss: 2.0035 - val_accuracy: 0.6240 - val_loss: 1.4792\n",
      "Epoch 5/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4935 - loss: 1.7489 - val_accuracy: 0.6777 - val_loss: 1.2212\n",
      "Epoch 6/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5690 - loss: 1.5025 - val_accuracy: 0.7273 - val_loss: 1.0580\n",
      "Epoch 7/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6284 - loss: 1.3292 - val_accuracy: 0.7624 - val_loss: 0.9274\n",
      "Epoch 8/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6575 - loss: 1.2129 - val_accuracy: 0.7851 - val_loss: 0.8501\n",
      "Epoch 9/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6757 - loss: 1.1352 - val_accuracy: 0.7975 - val_loss: 0.7792\n",
      "Epoch 10/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7355 - loss: 0.9799 - val_accuracy: 0.8326 - val_loss: 0.6966\n",
      "Epoch 11/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7158 - loss: 0.9740 - val_accuracy: 0.8244 - val_loss: 0.6445\n",
      "Epoch 12/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7477 - loss: 0.8706 - val_accuracy: 0.8409 - val_loss: 0.5947\n",
      "Epoch 13/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7865 - loss: 0.7527 - val_accuracy: 0.8430 - val_loss: 0.5697\n",
      "Epoch 14/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7902 - loss: 0.7357 - val_accuracy: 0.8492 - val_loss: 0.5314\n",
      "Epoch 15/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8130 - loss: 0.6887 - val_accuracy: 0.8698 - val_loss: 0.5132\n",
      "Epoch 16/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8330 - loss: 0.5991 - val_accuracy: 0.8657 - val_loss: 0.5228\n",
      "Epoch 17/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8470 - loss: 0.5552 - val_accuracy: 0.8636 - val_loss: 0.5245\n",
      "Epoch 18/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8398 - loss: 0.5565 - val_accuracy: 0.8843 - val_loss: 0.4650\n",
      "Epoch 19/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8387 - loss: 0.5140 - val_accuracy: 0.8884 - val_loss: 0.4780\n",
      "Epoch 20/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8721 - loss: 0.4604 - val_accuracy: 0.8719 - val_loss: 0.4966\n",
      "Epoch 21/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8620 - loss: 0.4761 - val_accuracy: 0.8822 - val_loss: 0.4854\n",
      "Epoch 22/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8713 - loss: 0.4294 - val_accuracy: 0.8802 - val_loss: 0.4650\n",
      "Epoch 23/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8866 - loss: 0.4420 - val_accuracy: 0.8884 - val_loss: 0.4428\n",
      "Epoch 24/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8778 - loss: 0.4299 - val_accuracy: 0.8822 - val_loss: 0.4456\n",
      "Epoch 25/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8850 - loss: 0.4052 - val_accuracy: 0.8926 - val_loss: 0.4192\n",
      "Epoch 26/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8911 - loss: 0.3703 - val_accuracy: 0.8843 - val_loss: 0.4616\n",
      "Epoch 27/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8936 - loss: 0.3686 - val_accuracy: 0.8822 - val_loss: 0.4558\n",
      "Epoch 28/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9063 - loss: 0.3319 - val_accuracy: 0.8905 - val_loss: 0.4535\n",
      "Epoch 29/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9077 - loss: 0.3419 - val_accuracy: 0.8905 - val_loss: 0.4512\n",
      "Epoch 30/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9071 - loss: 0.3410 - val_accuracy: 0.8926 - val_loss: 0.4527\n",
      "Epoch 31/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9030 - loss: 0.3253 - val_accuracy: 0.8988 - val_loss: 0.4370\n",
      "Epoch 32/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9170 - loss: 0.3094 - val_accuracy: 0.8946 - val_loss: 0.4273\n",
      "Epoch 33/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9117 - loss: 0.3097 - val_accuracy: 0.8822 - val_loss: 0.4437\n",
      "Epoch 34/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9128 - loss: 0.3289 - val_accuracy: 0.8926 - val_loss: 0.4357\n",
      "Epoch 35/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9119 - loss: 0.3150 - val_accuracy: 0.8905 - val_loss: 0.4609\n",
      "Epoch 36/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9201 - loss: 0.2756 - val_accuracy: 0.8988 - val_loss: 0.4598\n",
      "Epoch 37/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9142 - loss: 0.2780 - val_accuracy: 0.8946 - val_loss: 0.4532\n",
      "Epoch 38/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9289 - loss: 0.2515 - val_accuracy: 0.8884 - val_loss: 0.4411\n",
      "Epoch 39/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9150 - loss: 0.2861 - val_accuracy: 0.8905 - val_loss: 0.4592\n",
      "Epoch 40/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9329 - loss: 0.2592 - val_accuracy: 0.8926 - val_loss: 0.4588\n",
      "Epoch 41/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9303 - loss: 0.2489 - val_accuracy: 0.8905 - val_loss: 0.4334\n",
      "Epoch 42/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9383 - loss: 0.2293 - val_accuracy: 0.8967 - val_loss: 0.4513\n",
      "Epoch 43/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9364 - loss: 0.2074 - val_accuracy: 0.8760 - val_loss: 0.4782\n",
      "Epoch 44/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9284 - loss: 0.2501 - val_accuracy: 0.8843 - val_loss: 0.4534\n",
      "Epoch 45/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9274 - loss: 0.2436 - val_accuracy: 0.8905 - val_loss: 0.4616\n",
      "Epoch 46/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9178 - loss: 0.2503 - val_accuracy: 0.8884 - val_loss: 0.4898\n",
      "Epoch 47/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9423 - loss: 0.2190 - val_accuracy: 0.8926 - val_loss: 0.4547\n",
      "Epoch 48/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9391 - loss: 0.2336 - val_accuracy: 0.8926 - val_loss: 0.4692\n",
      "Epoch 49/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9350 - loss: 0.2285 - val_accuracy: 0.8967 - val_loss: 0.4765\n",
      "Epoch 50/50\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9399 - loss: 0.2077 - val_accuracy: 0.8967 - val_loss: 0.4791\n"
     ]
    }
   ],
   "source": [
    "# Train model with class weights if using weighted strategy\n",
    "if handler.strategy == \"weighted\":\n",
    "    print(\"Using Weighted Class Balancing!\")\n",
    "    history = model_2.fit(\n",
    "        data['train_dataset'],\n",
    "        validation_data=data['val_dataset'],\n",
    "        epochs=50,\n",
    "        # class_weight=data['class_weights']\n",
    "    )\n",
    "else:\n",
    "    print(\"Using NO Weighted Class Balancing!\")\n",
    "    history = model_2.fit(\n",
    "        data['train_dataset'],\n",
    "        validation_data=data['val_dataset'],\n",
    "        epochs=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(history, 'accuracy', 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.1240 - loss: 0.0777 - val_accuracy: 0.0923 - val_loss: 3.0537\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.1028 - loss: 0.0773 - val_accuracy: 0.0718 - val_loss: 3.0991\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.1153 - loss: 0.0764 - val_accuracy: 0.1026 - val_loss: 3.0550\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.1252 - loss: 0.0783 - val_accuracy: 0.0769 - val_loss: 3.0642\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.1073 - loss: 0.0702 - val_accuracy: 0.0769 - val_loss: 3.0796\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.1576 - loss: 0.0727 - val_accuracy: 0.1026 - val_loss: 3.0664\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.1148 - loss: 0.0740 - val_accuracy: 0.0769 - val_loss: 3.0594\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.1452 - loss: 0.0729 - val_accuracy: 0.0974 - val_loss: 3.0508\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.1107 - loss: 0.0767 - val_accuracy: 0.0974 - val_loss: 3.0539\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.1433 - loss: 0.0698 - val_accuracy: 0.0974 - val_loss: 3.0757\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    data['train_dataset'],\n",
    "    validation_data=data['val_dataset'],\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next(iter(data['train_dataset']))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model_2.predict(next(iter(data['train_dataset']))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Randoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 1],\n",
       "        [0, 1, 1],\n",
       "        [0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.matrix([[1, 0, 1], [0, 1, 1], [0, 0, 1]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B - (1 * I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 0],\n",
       "       [6, 6, 8],\n",
       "       [2, 2, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 9, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 0],\n",
       "       [0, 6, 0],\n",
       "       [1, 2, 8]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[2, 5, 0], [0, 6, 0], [1, 2, 8]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8., 2., 6.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 1, 0], [0, 1, 2], [0, 0, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0],\n",
       "       [0, 1, 2],\n",
       "       [0, 0, 3]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EigResult(eigenvalues=array([1., 1., 3.]), eigenvectors=array([[ 1.00000000e+00, -1.00000000e+00,  3.33333333e-01],\n",
       "       [ 0.00000000e+00,  2.22044605e-16,  6.66666667e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  6.66666667e-01]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_stock_data(tickers, days_back=30):\n",
    "    \"\"\"\n",
    "    Fetch stock data for given tickers for a specified number of days.\n",
    "    \n",
    "    Parameters:\n",
    "    tickers (list): List of stock ticker symbols (e.g., ['AAPL', 'GOOGL'])\n",
    "    days_back (int): Number of days of historical data to fetch\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing DataFrames with stock data for each ticker\n",
    "    \"\"\"\n",
    "    # Calculate date range\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days_back)\n",
    "    \n",
    "    stock_data = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Create ticker object\n",
    "            stock = yf.Ticker(ticker)\n",
    "            \n",
    "            # Fetch historical data\n",
    "            hist_data = stock.history(start=start_date, end=end_date)\n",
    "            \n",
    "            # Get additional stock info\n",
    "            info = stock.info\n",
    "            \n",
    "            # Add important info to the DataFrame\n",
    "            hist_data['Symbol'] = ticker\n",
    "            hist_data['Company_Name'] = info.get('longName', '')\n",
    "            hist_data['Industry'] = info.get('industry', '')\n",
    "            hist_data['Sector'] = info.get('sector', '')\n",
    "            hist_data['Market_Cap'] = info.get('marketCap', '')\n",
    "            \n",
    "            # Calculate daily returns\n",
    "            hist_data['Daily_Return'] = hist_data['Close'].pct_change()\n",
    "            \n",
    "            # Format the data\n",
    "            hist_data = hist_data.round(2)\n",
    "            \n",
    "            stock_data[ticker] = hist_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {str(e)}\")\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "def get_latest_prices(stock_data):\n",
    "    \"\"\"\n",
    "    Extract the most recent closing prices and details for each stock.\n",
    "    \n",
    "    Parameters:\n",
    "    stock_data (dict): Dictionary of stock DataFrames from fetch_stock_data\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Latest closing prices and details for each stock\n",
    "    \"\"\"\n",
    "    latest_data = []\n",
    "    \n",
    "    for ticker, data in stock_data.items():\n",
    "        if not data.empty:\n",
    "            latest = data.iloc[-1]\n",
    "            latest_data.append({\n",
    "                'Symbol': ticker,\n",
    "                'Company_Name': latest['Company_Name'],\n",
    "                'Close': latest['Close'],\n",
    "                'Volume': latest['Volume'],\n",
    "                'Daily_Return': latest['Daily_Return'],\n",
    "                'Industry': latest['Industry'],\n",
    "                'Sector': latest['Sector'],\n",
    "                'Market_Cap': latest['Market_Cap']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(latest_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
